{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T07:21:46.525588Z",
     "start_time": "2021-06-15T07:21:44.217277Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from gaminet import GAMINet\n",
    "from gaminet.utils import local_visualize\n",
    "from gaminet.utils import global_visualize_density\n",
    "from gaminet.utils import feature_importance_visualize\n",
    "from gaminet.utils import plot_trajectory\n",
    "from gaminet.utils import plot_regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-15T07:21:46.582410Z",
     "start_time": "2021-06-15T07:21:46.527767Z"
    }
   },
   "outputs": [],
   "source": [
    "def metric_wrapper(metric, scaler):\n",
    "    def wrapper(label, pred):\n",
    "        return metric(label, pred, scaler=scaler)\n",
    "    return wrapper\n",
    "\n",
    "def rmse(label, pred, scaler):\n",
    "    pred = scaler.inverse_transform(pred.reshape([-1, 1]))\n",
    "    label = scaler.inverse_transform(label.reshape([-1, 1]))\n",
    "    return np.sqrt(np.mean((pred - label)**2))\n",
    "\n",
    "def data_generator1(datanum, dist=\"uniform\", random_state=0):\n",
    "    \n",
    "    nfeatures = 100\n",
    "    np.random.seed(random_state)\n",
    "    x = np.random.uniform(0, 1, [datanum, nfeatures])\n",
    "    x1, x2, x3, x4, x5, x6 = [x[:, [i]] for i in range(6)]\n",
    "\n",
    "    def cliff(x1, x2):\n",
    "        # x1: -20,20\n",
    "        # x2: -10,5\n",
    "        x1 = (2 * x1 - 1) * 20\n",
    "        x2 = (2 * x2 - 1) * 7.5 - 2.5\n",
    "        term1 = -0.5 * x1 ** 2 / 100\n",
    "        term2 = -0.5 * (x2 + 0.03 * x1 ** 2 - 3) ** 2\n",
    "        y = 10 * np.exp(term1 + term2)\n",
    "        return  y\n",
    "\n",
    "    y = (8 * (x1 - 0.5) ** 2\n",
    "        + 0.1 * np.exp(-8 * x2 + 4)\n",
    "        + 3 * np.sin(2 * np.pi * x3 * x4)\n",
    "        + cliff(x5, x6)).reshape([-1,1]) + 1 * np.random.normal(0, 1, [datanum, 1])\n",
    "\n",
    "    task_type = \"Regression\"\n",
    "    meta_info = {\"X\" + str(i + 1):{'type':'continuous'} for i in range(nfeatures)}\n",
    "    meta_info.update({'Y':{'type':'target'}})         \n",
    "    for i, (key, item) in enumerate(meta_info.items()):\n",
    "        if item['type'] == 'target':\n",
    "            sy = MinMaxScaler((0, 1))\n",
    "            y = sy.fit_transform(y)\n",
    "            meta_info[key]['scaler'] = sy\n",
    "        else:\n",
    "            sx = MinMaxScaler((0, 1))\n",
    "            sx.fit([[0], [1]])\n",
    "            x[:,[i]] = sx.transform(x[:,[i]])\n",
    "            meta_info[key]['scaler'] = sx\n",
    "\n",
    "    train_x, test_x, train_y, test_y = train_test_split(x, y, test_size=0.2, random_state=random_state)\n",
    "    return train_x, test_x, train_y, test_y, task_type, meta_info, metric_wrapper(rmse, sy)\n",
    "\n",
    "random_state = 0\n",
    "train_x, test_x, train_y, test_y, task_type, meta_info, get_metric = data_generator1(datanum=10000, random_state=random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train GAMI-Net "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-06-15T07:21:41.697Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################GAMI-Net training start.####################\n",
      "##########Stage 1: main effect training start.##########\n",
      "Main effects training epoch: 1, train loss: 0.03521, val loss: 0.03572\n",
      "Main effects training epoch: 2, train loss: 0.02014, val loss: 0.02092\n",
      "Main effects training epoch: 3, train loss: 0.01960, val loss: 0.02055\n",
      "Main effects training epoch: 4, train loss: 0.01937, val loss: 0.02050\n",
      "Main effects training epoch: 5, train loss: 0.01971, val loss: 0.02044\n",
      "Main effects training epoch: 6, train loss: 0.01935, val loss: 0.02037\n",
      "Main effects training epoch: 7, train loss: 0.01879, val loss: 0.02034\n",
      "Main effects training epoch: 8, train loss: 0.01924, val loss: 0.02022\n",
      "Main effects training epoch: 9, train loss: 0.01952, val loss: 0.02017\n",
      "Main effects training epoch: 10, train loss: 0.01893, val loss: 0.02004\n",
      "Main effects training epoch: 11, train loss: 0.01882, val loss: 0.01984\n",
      "Main effects training epoch: 12, train loss: 0.01888, val loss: 0.01966\n",
      "Main effects training epoch: 13, train loss: 0.01857, val loss: 0.01932\n",
      "Main effects training epoch: 14, train loss: 0.01777, val loss: 0.01895\n",
      "Main effects training epoch: 15, train loss: 0.01730, val loss: 0.01848\n",
      "Main effects training epoch: 16, train loss: 0.01637, val loss: 0.01790\n",
      "Main effects training epoch: 17, train loss: 0.01600, val loss: 0.01732\n",
      "Main effects training epoch: 18, train loss: 0.01578, val loss: 0.01688\n",
      "Main effects training epoch: 19, train loss: 0.01499, val loss: 0.01633\n",
      "Main effects training epoch: 20, train loss: 0.01466, val loss: 0.01596\n",
      "Main effects training epoch: 21, train loss: 0.01420, val loss: 0.01564\n",
      "Main effects training epoch: 22, train loss: 0.01431, val loss: 0.01542\n",
      "Main effects training epoch: 23, train loss: 0.01393, val loss: 0.01516\n",
      "Main effects training epoch: 24, train loss: 0.01373, val loss: 0.01495\n",
      "Main effects training epoch: 25, train loss: 0.01320, val loss: 0.01477\n",
      "Main effects training epoch: 26, train loss: 0.01353, val loss: 0.01462\n",
      "Main effects training epoch: 27, train loss: 0.01331, val loss: 0.01443\n",
      "Main effects training epoch: 28, train loss: 0.01298, val loss: 0.01430\n",
      "Main effects training epoch: 29, train loss: 0.01302, val loss: 0.01418\n",
      "Main effects training epoch: 30, train loss: 0.01307, val loss: 0.01397\n",
      "Main effects training epoch: 31, train loss: 0.01274, val loss: 0.01384\n",
      "Main effects training epoch: 32, train loss: 0.01277, val loss: 0.01370\n",
      "Main effects training epoch: 33, train loss: 0.01264, val loss: 0.01366\n",
      "Main effects training epoch: 34, train loss: 0.01246, val loss: 0.01348\n",
      "Main effects training epoch: 35, train loss: 0.01258, val loss: 0.01339\n",
      "Main effects training epoch: 36, train loss: 0.01249, val loss: 0.01332\n",
      "Main effects training epoch: 37, train loss: 0.01249, val loss: 0.01324\n",
      "Main effects training epoch: 38, train loss: 0.01224, val loss: 0.01318\n",
      "Main effects training epoch: 39, train loss: 0.01231, val loss: 0.01315\n",
      "Main effects training epoch: 40, train loss: 0.01217, val loss: 0.01304\n",
      "Main effects training epoch: 41, train loss: 0.01211, val loss: 0.01300\n",
      "Main effects training epoch: 42, train loss: 0.01237, val loss: 0.01294\n",
      "Main effects training epoch: 43, train loss: 0.01224, val loss: 0.01300\n",
      "Main effects training epoch: 44, train loss: 0.01202, val loss: 0.01292\n",
      "Main effects training epoch: 45, train loss: 0.01203, val loss: 0.01287\n",
      "Main effects training epoch: 46, train loss: 0.01196, val loss: 0.01279\n",
      "Main effects training epoch: 47, train loss: 0.01170, val loss: 0.01279\n",
      "Main effects training epoch: 48, train loss: 0.01209, val loss: 0.01272\n",
      "Main effects training epoch: 49, train loss: 0.01205, val loss: 0.01272\n",
      "Main effects training epoch: 50, train loss: 0.01190, val loss: 0.01271\n",
      "Main effects training epoch: 51, train loss: 0.01178, val loss: 0.01265\n",
      "Main effects training epoch: 52, train loss: 0.01168, val loss: 0.01262\n",
      "Main effects training epoch: 53, train loss: 0.01181, val loss: 0.01263\n",
      "Main effects training epoch: 54, train loss: 0.01194, val loss: 0.01260\n",
      "Main effects training epoch: 55, train loss: 0.01187, val loss: 0.01258\n",
      "Main effects training epoch: 56, train loss: 0.01190, val loss: 0.01268\n",
      "Main effects training epoch: 57, train loss: 0.01177, val loss: 0.01259\n",
      "Main effects training epoch: 58, train loss: 0.01195, val loss: 0.01262\n",
      "Main effects training epoch: 59, train loss: 0.01184, val loss: 0.01263\n",
      "Main effects training epoch: 60, train loss: 0.01180, val loss: 0.01252\n",
      "Main effects training epoch: 61, train loss: 0.01183, val loss: 0.01251\n",
      "Main effects training epoch: 62, train loss: 0.01176, val loss: 0.01258\n",
      "Main effects training epoch: 63, train loss: 0.01181, val loss: 0.01259\n",
      "Main effects training epoch: 64, train loss: 0.01155, val loss: 0.01253\n",
      "Main effects training epoch: 65, train loss: 0.01172, val loss: 0.01266\n",
      "Main effects training epoch: 66, train loss: 0.01197, val loss: 0.01250\n",
      "Main effects training epoch: 67, train loss: 0.01156, val loss: 0.01249\n",
      "Main effects training epoch: 68, train loss: 0.01153, val loss: 0.01258\n",
      "Main effects training epoch: 69, train loss: 0.01144, val loss: 0.01247\n",
      "Main effects training epoch: 70, train loss: 0.01166, val loss: 0.01246\n",
      "Main effects training epoch: 71, train loss: 0.01145, val loss: 0.01249\n",
      "Main effects training epoch: 72, train loss: 0.01157, val loss: 0.01247\n",
      "Main effects training epoch: 73, train loss: 0.01157, val loss: 0.01247\n",
      "Main effects training epoch: 74, train loss: 0.01159, val loss: 0.01249\n",
      "Main effects training epoch: 75, train loss: 0.01155, val loss: 0.01251\n",
      "Main effects training epoch: 76, train loss: 0.01139, val loss: 0.01250\n",
      "Main effects training epoch: 77, train loss: 0.01163, val loss: 0.01243\n",
      "Main effects training epoch: 78, train loss: 0.01166, val loss: 0.01244\n",
      "Main effects training epoch: 79, train loss: 0.01139, val loss: 0.01241\n",
      "Main effects training epoch: 80, train loss: 0.01164, val loss: 0.01249\n",
      "Main effects training epoch: 81, train loss: 0.01150, val loss: 0.01242\n",
      "Main effects training epoch: 82, train loss: 0.01131, val loss: 0.01243\n",
      "Main effects training epoch: 83, train loss: 0.01162, val loss: 0.01266\n",
      "Main effects training epoch: 84, train loss: 0.01153, val loss: 0.01252\n",
      "Main effects training epoch: 85, train loss: 0.01154, val loss: 0.01241\n",
      "Main effects training epoch: 86, train loss: 0.01114, val loss: 0.01239\n",
      "Main effects training epoch: 87, train loss: 0.01135, val loss: 0.01242\n",
      "Main effects training epoch: 88, train loss: 0.01136, val loss: 0.01241\n",
      "Main effects training epoch: 89, train loss: 0.01138, val loss: 0.01242\n",
      "Main effects training epoch: 90, train loss: 0.01166, val loss: 0.01245\n",
      "Main effects training epoch: 91, train loss: 0.01134, val loss: 0.01243\n",
      "Main effects training epoch: 92, train loss: 0.01134, val loss: 0.01239\n",
      "Main effects training epoch: 93, train loss: 0.01157, val loss: 0.01242\n",
      "Main effects training epoch: 94, train loss: 0.01136, val loss: 0.01240\n",
      "Main effects training epoch: 95, train loss: 0.01134, val loss: 0.01241\n",
      "Main effects training epoch: 96, train loss: 0.01166, val loss: 0.01239\n",
      "Main effects training epoch: 97, train loss: 0.01149, val loss: 0.01245\n",
      "Main effects training epoch: 98, train loss: 0.01124, val loss: 0.01240\n",
      "Main effects training epoch: 99, train loss: 0.01127, val loss: 0.01239\n",
      "Main effects training epoch: 100, train loss: 0.01132, val loss: 0.01240\n",
      "Main effects training epoch: 101, train loss: 0.01112, val loss: 0.01240\n",
      "Main effects training epoch: 102, train loss: 0.01177, val loss: 0.01267\n",
      "Main effects training epoch: 103, train loss: 0.01135, val loss: 0.01238\n",
      "Main effects training epoch: 104, train loss: 0.01143, val loss: 0.01243\n",
      "Main effects training epoch: 105, train loss: 0.01136, val loss: 0.01238\n",
      "Main effects training epoch: 106, train loss: 0.01133, val loss: 0.01247\n",
      "Main effects training epoch: 107, train loss: 0.01132, val loss: 0.01249\n",
      "Main effects training epoch: 108, train loss: 0.01136, val loss: 0.01237\n",
      "Main effects training epoch: 109, train loss: 0.01142, val loss: 0.01251\n",
      "Main effects training epoch: 110, train loss: 0.01137, val loss: 0.01242\n",
      "Main effects training epoch: 111, train loss: 0.01133, val loss: 0.01235\n",
      "Main effects training epoch: 112, train loss: 0.01116, val loss: 0.01236\n",
      "Main effects training epoch: 113, train loss: 0.01135, val loss: 0.01235\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main effects training epoch: 114, train loss: 0.01131, val loss: 0.01237\n",
      "Main effects training epoch: 115, train loss: 0.01127, val loss: 0.01235\n",
      "Main effects training epoch: 116, train loss: 0.01117, val loss: 0.01240\n",
      "Main effects training epoch: 117, train loss: 0.01136, val loss: 0.01239\n",
      "Main effects training epoch: 118, train loss: 0.01147, val loss: 0.01237\n",
      "Main effects training epoch: 119, train loss: 0.01130, val loss: 0.01235\n",
      "Main effects training epoch: 120, train loss: 0.01121, val loss: 0.01233\n",
      "Main effects training epoch: 121, train loss: 0.01111, val loss: 0.01234\n",
      "Main effects training epoch: 122, train loss: 0.01123, val loss: 0.01239\n",
      "Main effects training epoch: 123, train loss: 0.01134, val loss: 0.01242\n",
      "Main effects training epoch: 124, train loss: 0.01104, val loss: 0.01231\n",
      "Main effects training epoch: 125, train loss: 0.01120, val loss: 0.01246\n",
      "Main effects training epoch: 126, train loss: 0.01120, val loss: 0.01237\n",
      "Main effects training epoch: 127, train loss: 0.01133, val loss: 0.01236\n",
      "Main effects training epoch: 128, train loss: 0.01145, val loss: 0.01241\n",
      "Main effects training epoch: 129, train loss: 0.01114, val loss: 0.01227\n",
      "Main effects training epoch: 130, train loss: 0.01102, val loss: 0.01229\n",
      "Main effects training epoch: 131, train loss: 0.01128, val loss: 0.01230\n",
      "Main effects training epoch: 132, train loss: 0.01100, val loss: 0.01236\n",
      "Main effects training epoch: 133, train loss: 0.01119, val loss: 0.01230\n",
      "Main effects training epoch: 134, train loss: 0.01103, val loss: 0.01227\n",
      "Main effects training epoch: 135, train loss: 0.01101, val loss: 0.01226\n",
      "Main effects training epoch: 136, train loss: 0.01093, val loss: 0.01224\n",
      "Main effects training epoch: 137, train loss: 0.01105, val loss: 0.01239\n",
      "Main effects training epoch: 138, train loss: 0.01110, val loss: 0.01222\n",
      "Main effects training epoch: 139, train loss: 0.01118, val loss: 0.01229\n",
      "Main effects training epoch: 140, train loss: 0.01109, val loss: 0.01222\n",
      "Main effects training epoch: 141, train loss: 0.01102, val loss: 0.01221\n",
      "Main effects training epoch: 142, train loss: 0.01116, val loss: 0.01218\n",
      "Main effects training epoch: 143, train loss: 0.01091, val loss: 0.01222\n",
      "Main effects training epoch: 144, train loss: 0.01115, val loss: 0.01222\n",
      "Main effects training epoch: 145, train loss: 0.01137, val loss: 0.01231\n",
      "Main effects training epoch: 146, train loss: 0.01080, val loss: 0.01214\n",
      "Main effects training epoch: 147, train loss: 0.01132, val loss: 0.01214\n",
      "Main effects training epoch: 148, train loss: 0.01114, val loss: 0.01214\n",
      "Main effects training epoch: 149, train loss: 0.01098, val loss: 0.01216\n",
      "Main effects training epoch: 150, train loss: 0.01111, val loss: 0.01218\n",
      "Main effects training epoch: 151, train loss: 0.01090, val loss: 0.01209\n",
      "Main effects training epoch: 152, train loss: 0.01083, val loss: 0.01218\n",
      "Main effects training epoch: 153, train loss: 0.01096, val loss: 0.01207\n",
      "Main effects training epoch: 154, train loss: 0.01081, val loss: 0.01209\n",
      "Main effects training epoch: 155, train loss: 0.01084, val loss: 0.01211\n",
      "Main effects training epoch: 156, train loss: 0.01110, val loss: 0.01218\n",
      "Main effects training epoch: 157, train loss: 0.01080, val loss: 0.01213\n",
      "Main effects training epoch: 158, train loss: 0.01063, val loss: 0.01205\n",
      "Main effects training epoch: 159, train loss: 0.01102, val loss: 0.01213\n",
      "Main effects training epoch: 160, train loss: 0.01081, val loss: 0.01202\n",
      "Main effects training epoch: 161, train loss: 0.01079, val loss: 0.01212\n",
      "Main effects training epoch: 162, train loss: 0.01105, val loss: 0.01208\n",
      "Main effects training epoch: 163, train loss: 0.01097, val loss: 0.01215\n",
      "Main effects training epoch: 164, train loss: 0.01089, val loss: 0.01205\n",
      "Main effects training epoch: 165, train loss: 0.01086, val loss: 0.01210\n",
      "Main effects training epoch: 166, train loss: 0.01092, val loss: 0.01205\n",
      "Main effects training epoch: 167, train loss: 0.01091, val loss: 0.01207\n",
      "Main effects training epoch: 168, train loss: 0.01097, val loss: 0.01207\n",
      "Main effects training epoch: 169, train loss: 0.01072, val loss: 0.01208\n",
      "Main effects training epoch: 170, train loss: 0.01072, val loss: 0.01199\n",
      "Main effects training epoch: 171, train loss: 0.01075, val loss: 0.01216\n",
      "Main effects training epoch: 172, train loss: 0.01120, val loss: 0.01248\n",
      "Main effects training epoch: 173, train loss: 0.01080, val loss: 0.01205\n",
      "Main effects training epoch: 174, train loss: 0.01115, val loss: 0.01212\n",
      "Main effects training epoch: 175, train loss: 0.01074, val loss: 0.01208\n",
      "Main effects training epoch: 176, train loss: 0.01105, val loss: 0.01200\n",
      "Main effects training epoch: 177, train loss: 0.01102, val loss: 0.01211\n",
      "Main effects training epoch: 178, train loss: 0.01122, val loss: 0.01206\n",
      "Main effects training epoch: 179, train loss: 0.01079, val loss: 0.01205\n",
      "Main effects training epoch: 180, train loss: 0.01109, val loss: 0.01200\n",
      "Main effects training epoch: 181, train loss: 0.01104, val loss: 0.01196\n",
      "Main effects training epoch: 182, train loss: 0.01115, val loss: 0.01198\n",
      "Main effects training epoch: 183, train loss: 0.01092, val loss: 0.01193\n",
      "Main effects training epoch: 184, train loss: 0.01102, val loss: 0.01193\n",
      "Main effects training epoch: 185, train loss: 0.01094, val loss: 0.01199\n",
      "Main effects training epoch: 186, train loss: 0.01064, val loss: 0.01189\n",
      "Main effects training epoch: 187, train loss: 0.01080, val loss: 0.01199\n",
      "Main effects training epoch: 188, train loss: 0.01080, val loss: 0.01190\n",
      "Main effects training epoch: 189, train loss: 0.01070, val loss: 0.01201\n",
      "Main effects training epoch: 190, train loss: 0.01081, val loss: 0.01193\n",
      "Main effects training epoch: 191, train loss: 0.01084, val loss: 0.01195\n",
      "Main effects training epoch: 192, train loss: 0.01076, val loss: 0.01193\n",
      "Main effects training epoch: 193, train loss: 0.01072, val loss: 0.01194\n",
      "Main effects training epoch: 194, train loss: 0.01086, val loss: 0.01189\n",
      "Main effects training epoch: 195, train loss: 0.01096, val loss: 0.01191\n",
      "Main effects training epoch: 196, train loss: 0.01087, val loss: 0.01188\n",
      "Main effects training epoch: 197, train loss: 0.01081, val loss: 0.01188\n",
      "Main effects training epoch: 198, train loss: 0.01080, val loss: 0.01191\n",
      "Main effects training epoch: 199, train loss: 0.01059, val loss: 0.01194\n",
      "Main effects training epoch: 200, train loss: 0.01083, val loss: 0.01212\n",
      "Main effects training epoch: 201, train loss: 0.01061, val loss: 0.01188\n",
      "Main effects training epoch: 202, train loss: 0.01103, val loss: 0.01195\n",
      "Main effects training epoch: 203, train loss: 0.01066, val loss: 0.01204\n",
      "Main effects training epoch: 204, train loss: 0.01091, val loss: 0.01193\n",
      "Main effects training epoch: 205, train loss: 0.01084, val loss: 0.01186\n",
      "Main effects training epoch: 206, train loss: 0.01084, val loss: 0.01189\n",
      "Main effects training epoch: 207, train loss: 0.01086, val loss: 0.01187\n",
      "Main effects training epoch: 208, train loss: 0.01068, val loss: 0.01190\n",
      "Main effects training epoch: 209, train loss: 0.01074, val loss: 0.01191\n",
      "Main effects training epoch: 210, train loss: 0.01068, val loss: 0.01201\n",
      "Main effects training epoch: 211, train loss: 0.01079, val loss: 0.01194\n",
      "Main effects training epoch: 212, train loss: 0.01089, val loss: 0.01187\n",
      "Main effects training epoch: 213, train loss: 0.01090, val loss: 0.01194\n",
      "Main effects training epoch: 214, train loss: 0.01069, val loss: 0.01201\n",
      "Main effects training epoch: 215, train loss: 0.01089, val loss: 0.01197\n",
      "Main effects training epoch: 216, train loss: 0.01068, val loss: 0.01186\n",
      "Main effects training epoch: 217, train loss: 0.01101, val loss: 0.01202\n",
      "Main effects training epoch: 218, train loss: 0.01088, val loss: 0.01191\n",
      "Main effects training epoch: 219, train loss: 0.01083, val loss: 0.01188\n",
      "Main effects training epoch: 220, train loss: 0.01082, val loss: 0.01191\n",
      "Main effects training epoch: 221, train loss: 0.01091, val loss: 0.01190\n",
      "Main effects training epoch: 222, train loss: 0.01086, val loss: 0.01198\n",
      "Main effects training epoch: 223, train loss: 0.01060, val loss: 0.01198\n",
      "Main effects training epoch: 224, train loss: 0.01105, val loss: 0.01233\n",
      "Main effects training epoch: 225, train loss: 0.01088, val loss: 0.01208\n",
      "Main effects training epoch: 226, train loss: 0.01078, val loss: 0.01190\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main effects training epoch: 227, train loss: 0.01081, val loss: 0.01208\n",
      "Main effects training epoch: 228, train loss: 0.01087, val loss: 0.01213\n",
      "Main effects training epoch: 229, train loss: 0.01066, val loss: 0.01194\n",
      "Main effects training epoch: 230, train loss: 0.01064, val loss: 0.01191\n",
      "Main effects training epoch: 231, train loss: 0.01088, val loss: 0.01187\n",
      "Main effects training epoch: 232, train loss: 0.01079, val loss: 0.01189\n",
      "Main effects training epoch: 233, train loss: 0.01083, val loss: 0.01187\n",
      "Main effects training epoch: 234, train loss: 0.01093, val loss: 0.01220\n",
      "Main effects training epoch: 235, train loss: 0.01068, val loss: 0.01197\n",
      "Main effects training epoch: 236, train loss: 0.01069, val loss: 0.01192\n",
      "Main effects training epoch: 237, train loss: 0.01058, val loss: 0.01189\n",
      "Main effects training epoch: 238, train loss: 0.01078, val loss: 0.01187\n",
      "Main effects training epoch: 239, train loss: 0.01097, val loss: 0.01206\n",
      "Main effects training epoch: 240, train loss: 0.01057, val loss: 0.01191\n",
      "Main effects training epoch: 241, train loss: 0.01072, val loss: 0.01188\n",
      "Main effects training epoch: 242, train loss: 0.01084, val loss: 0.01195\n",
      "Main effects training epoch: 243, train loss: 0.01093, val loss: 0.01187\n",
      "Main effects training epoch: 244, train loss: 0.01077, val loss: 0.01189\n",
      "Main effects training epoch: 245, train loss: 0.01086, val loss: 0.01196\n",
      "Main effects training epoch: 246, train loss: 0.01094, val loss: 0.01191\n",
      "Main effects training epoch: 247, train loss: 0.01079, val loss: 0.01188\n",
      "Main effects training epoch: 248, train loss: 0.01056, val loss: 0.01190\n",
      "Main effects training epoch: 249, train loss: 0.01082, val loss: 0.01207\n",
      "Main effects training epoch: 250, train loss: 0.01076, val loss: 0.01192\n",
      "Main effects training epoch: 251, train loss: 0.01091, val loss: 0.01192\n",
      "Main effects training epoch: 252, train loss: 0.01047, val loss: 0.01194\n",
      "Main effects training epoch: 253, train loss: 0.01089, val loss: 0.01209\n",
      "Main effects training epoch: 254, train loss: 0.01087, val loss: 0.01202\n",
      "Main effects training epoch: 255, train loss: 0.01061, val loss: 0.01191\n",
      "Main effects training epoch: 256, train loss: 0.01069, val loss: 0.01190\n",
      "Early stop at epoch 256, with validation loss: 0.01190\n",
      "##########Stage 1: main effect training stop.##########\n",
      "##########Stage 2: interaction training start.##########\n",
      "Interaction training epoch: 1, train loss: 0.01064, val loss: 0.01113\n",
      "Interaction training epoch: 2, train loss: 0.01034, val loss: 0.01077\n",
      "Interaction training epoch: 3, train loss: 0.01016, val loss: 0.01040\n",
      "Interaction training epoch: 4, train loss: 0.00963, val loss: 0.01010\n",
      "Interaction training epoch: 5, train loss: 0.00924, val loss: 0.00973\n",
      "Interaction training epoch: 6, train loss: 0.00930, val loss: 0.00954\n",
      "Interaction training epoch: 7, train loss: 0.00898, val loss: 0.00928\n",
      "Interaction training epoch: 8, train loss: 0.00856, val loss: 0.00896\n",
      "Interaction training epoch: 9, train loss: 0.00827, val loss: 0.00862\n",
      "Interaction training epoch: 10, train loss: 0.00801, val loss: 0.00833\n",
      "Interaction training epoch: 11, train loss: 0.00785, val loss: 0.00801\n",
      "Interaction training epoch: 12, train loss: 0.00760, val loss: 0.00778\n",
      "Interaction training epoch: 13, train loss: 0.00718, val loss: 0.00747\n",
      "Interaction training epoch: 14, train loss: 0.00705, val loss: 0.00730\n",
      "Interaction training epoch: 15, train loss: 0.00689, val loss: 0.00714\n",
      "Interaction training epoch: 16, train loss: 0.00678, val loss: 0.00701\n",
      "Interaction training epoch: 17, train loss: 0.00651, val loss: 0.00686\n",
      "Interaction training epoch: 18, train loss: 0.00654, val loss: 0.00668\n",
      "Interaction training epoch: 19, train loss: 0.00627, val loss: 0.00659\n",
      "Interaction training epoch: 20, train loss: 0.00642, val loss: 0.00660\n",
      "Interaction training epoch: 21, train loss: 0.00619, val loss: 0.00642\n",
      "Interaction training epoch: 22, train loss: 0.00608, val loss: 0.00633\n",
      "Interaction training epoch: 23, train loss: 0.00604, val loss: 0.00626\n",
      "Interaction training epoch: 24, train loss: 0.00593, val loss: 0.00620\n",
      "Interaction training epoch: 25, train loss: 0.00596, val loss: 0.00614\n",
      "Interaction training epoch: 26, train loss: 0.00584, val loss: 0.00611\n",
      "Interaction training epoch: 27, train loss: 0.00585, val loss: 0.00608\n",
      "Interaction training epoch: 28, train loss: 0.00586, val loss: 0.00598\n",
      "Interaction training epoch: 29, train loss: 0.00591, val loss: 0.00595\n",
      "Interaction training epoch: 30, train loss: 0.00572, val loss: 0.00594\n",
      "Interaction training epoch: 31, train loss: 0.00574, val loss: 0.00593\n",
      "Interaction training epoch: 32, train loss: 0.00577, val loss: 0.00588\n",
      "Interaction training epoch: 33, train loss: 0.00567, val loss: 0.00585\n",
      "Interaction training epoch: 34, train loss: 0.00568, val loss: 0.00580\n",
      "Interaction training epoch: 35, train loss: 0.00557, val loss: 0.00581\n",
      "Interaction training epoch: 36, train loss: 0.00550, val loss: 0.00573\n",
      "Interaction training epoch: 37, train loss: 0.00544, val loss: 0.00577\n",
      "Interaction training epoch: 38, train loss: 0.00548, val loss: 0.00571\n",
      "Interaction training epoch: 39, train loss: 0.00562, val loss: 0.00574\n",
      "Interaction training epoch: 40, train loss: 0.00548, val loss: 0.00568\n",
      "Interaction training epoch: 41, train loss: 0.00554, val loss: 0.00567\n",
      "Interaction training epoch: 42, train loss: 0.00559, val loss: 0.00563\n",
      "Interaction training epoch: 43, train loss: 0.00558, val loss: 0.00564\n",
      "Interaction training epoch: 44, train loss: 0.00540, val loss: 0.00562\n",
      "Interaction training epoch: 45, train loss: 0.00552, val loss: 0.00566\n",
      "Interaction training epoch: 46, train loss: 0.00513, val loss: 0.00558\n",
      "Interaction training epoch: 47, train loss: 0.00528, val loss: 0.00559\n",
      "Interaction training epoch: 48, train loss: 0.00540, val loss: 0.00555\n",
      "Interaction training epoch: 49, train loss: 0.00544, val loss: 0.00554\n",
      "Interaction training epoch: 50, train loss: 0.00543, val loss: 0.00553\n",
      "Interaction training epoch: 51, train loss: 0.00526, val loss: 0.00552\n",
      "Interaction training epoch: 52, train loss: 0.00511, val loss: 0.00549\n",
      "Interaction training epoch: 53, train loss: 0.00528, val loss: 0.00548\n",
      "Interaction training epoch: 54, train loss: 0.00531, val loss: 0.00550\n",
      "Interaction training epoch: 55, train loss: 0.00533, val loss: 0.00550\n",
      "Interaction training epoch: 56, train loss: 0.00522, val loss: 0.00546\n",
      "Interaction training epoch: 57, train loss: 0.00507, val loss: 0.00546\n",
      "Interaction training epoch: 58, train loss: 0.00520, val loss: 0.00545\n",
      "Interaction training epoch: 59, train loss: 0.00521, val loss: 0.00543\n",
      "Interaction training epoch: 60, train loss: 0.00515, val loss: 0.00543\n",
      "Interaction training epoch: 61, train loss: 0.00530, val loss: 0.00541\n",
      "Interaction training epoch: 62, train loss: 0.00514, val loss: 0.00541\n",
      "Interaction training epoch: 63, train loss: 0.00529, val loss: 0.00543\n",
      "Interaction training epoch: 64, train loss: 0.00530, val loss: 0.00543\n",
      "Interaction training epoch: 65, train loss: 0.00500, val loss: 0.00540\n",
      "Interaction training epoch: 66, train loss: 0.00519, val loss: 0.00535\n",
      "Interaction training epoch: 67, train loss: 0.00528, val loss: 0.00536\n",
      "Interaction training epoch: 68, train loss: 0.00524, val loss: 0.00535\n",
      "Interaction training epoch: 69, train loss: 0.00507, val loss: 0.00533\n",
      "Interaction training epoch: 70, train loss: 0.00504, val loss: 0.00534\n",
      "Interaction training epoch: 71, train loss: 0.00518, val loss: 0.00533\n",
      "Interaction training epoch: 72, train loss: 0.00506, val loss: 0.00532\n",
      "Interaction training epoch: 73, train loss: 0.00519, val loss: 0.00532\n",
      "Interaction training epoch: 74, train loss: 0.00521, val loss: 0.00533\n",
      "Interaction training epoch: 75, train loss: 0.00511, val loss: 0.00527\n",
      "Interaction training epoch: 76, train loss: 0.00513, val loss: 0.00533\n",
      "Interaction training epoch: 77, train loss: 0.00515, val loss: 0.00529\n",
      "Interaction training epoch: 78, train loss: 0.00498, val loss: 0.00528\n",
      "Interaction training epoch: 79, train loss: 0.00509, val loss: 0.00526\n",
      "Interaction training epoch: 80, train loss: 0.00505, val loss: 0.00531\n",
      "Interaction training epoch: 81, train loss: 0.00505, val loss: 0.00523\n",
      "Interaction training epoch: 82, train loss: 0.00513, val loss: 0.00521\n",
      "Interaction training epoch: 83, train loss: 0.00519, val loss: 0.00521\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interaction training epoch: 84, train loss: 0.00517, val loss: 0.00519\n",
      "Interaction training epoch: 85, train loss: 0.00497, val loss: 0.00518\n",
      "Interaction training epoch: 86, train loss: 0.00489, val loss: 0.00521\n",
      "Interaction training epoch: 87, train loss: 0.00501, val loss: 0.00517\n",
      "Interaction training epoch: 88, train loss: 0.00492, val loss: 0.00521\n",
      "Interaction training epoch: 89, train loss: 0.00506, val loss: 0.00522\n",
      "Interaction training epoch: 90, train loss: 0.00483, val loss: 0.00511\n",
      "Interaction training epoch: 91, train loss: 0.00506, val loss: 0.00512\n",
      "Interaction training epoch: 92, train loss: 0.00492, val loss: 0.00512\n",
      "Interaction training epoch: 93, train loss: 0.00494, val loss: 0.00518\n",
      "Interaction training epoch: 94, train loss: 0.00489, val loss: 0.00504\n",
      "Interaction training epoch: 95, train loss: 0.00489, val loss: 0.00503\n",
      "Interaction training epoch: 96, train loss: 0.00488, val loss: 0.00499\n",
      "Interaction training epoch: 97, train loss: 0.00481, val loss: 0.00502\n",
      "Interaction training epoch: 98, train loss: 0.00474, val loss: 0.00496\n",
      "Interaction training epoch: 99, train loss: 0.00480, val loss: 0.00494\n",
      "Interaction training epoch: 100, train loss: 0.00481, val loss: 0.00498\n",
      "Interaction training epoch: 101, train loss: 0.00482, val loss: 0.00493\n",
      "Interaction training epoch: 102, train loss: 0.00477, val loss: 0.00494\n",
      "Interaction training epoch: 103, train loss: 0.00485, val loss: 0.00491\n",
      "Interaction training epoch: 104, train loss: 0.00470, val loss: 0.00485\n",
      "Interaction training epoch: 105, train loss: 0.00466, val loss: 0.00481\n",
      "Interaction training epoch: 106, train loss: 0.00467, val loss: 0.00477\n",
      "Interaction training epoch: 107, train loss: 0.00458, val loss: 0.00480\n",
      "Interaction training epoch: 108, train loss: 0.00452, val loss: 0.00471\n",
      "Interaction training epoch: 109, train loss: 0.00450, val loss: 0.00472\n",
      "Interaction training epoch: 110, train loss: 0.00449, val loss: 0.00472\n",
      "Interaction training epoch: 111, train loss: 0.00468, val loss: 0.00473\n",
      "Interaction training epoch: 112, train loss: 0.00439, val loss: 0.00461\n",
      "Interaction training epoch: 113, train loss: 0.00441, val loss: 0.00457\n",
      "Interaction training epoch: 114, train loss: 0.00441, val loss: 0.00457\n",
      "Interaction training epoch: 115, train loss: 0.00441, val loss: 0.00452\n",
      "Interaction training epoch: 116, train loss: 0.00441, val loss: 0.00454\n",
      "Interaction training epoch: 117, train loss: 0.00448, val loss: 0.00456\n",
      "Interaction training epoch: 118, train loss: 0.00440, val loss: 0.00454\n",
      "Interaction training epoch: 119, train loss: 0.00422, val loss: 0.00444\n",
      "Interaction training epoch: 120, train loss: 0.00427, val loss: 0.00441\n",
      "Interaction training epoch: 121, train loss: 0.00429, val loss: 0.00438\n",
      "Interaction training epoch: 122, train loss: 0.00422, val loss: 0.00436\n",
      "Interaction training epoch: 123, train loss: 0.00412, val loss: 0.00432\n",
      "Interaction training epoch: 124, train loss: 0.00416, val loss: 0.00432\n",
      "Interaction training epoch: 125, train loss: 0.00412, val loss: 0.00427\n",
      "Interaction training epoch: 126, train loss: 0.00411, val loss: 0.00423\n",
      "Interaction training epoch: 127, train loss: 0.00430, val loss: 0.00430\n",
      "Interaction training epoch: 128, train loss: 0.00409, val loss: 0.00422\n",
      "Interaction training epoch: 129, train loss: 0.00407, val loss: 0.00423\n",
      "Interaction training epoch: 130, train loss: 0.00398, val loss: 0.00416\n",
      "Interaction training epoch: 131, train loss: 0.00405, val loss: 0.00421\n",
      "Interaction training epoch: 132, train loss: 0.00387, val loss: 0.00412\n",
      "Interaction training epoch: 133, train loss: 0.00392, val loss: 0.00411\n",
      "Interaction training epoch: 134, train loss: 0.00394, val loss: 0.00415\n",
      "Interaction training epoch: 135, train loss: 0.00388, val loss: 0.00405\n",
      "Interaction training epoch: 136, train loss: 0.00382, val loss: 0.00403\n",
      "Interaction training epoch: 137, train loss: 0.00384, val loss: 0.00404\n",
      "Interaction training epoch: 138, train loss: 0.00382, val loss: 0.00403\n",
      "Interaction training epoch: 139, train loss: 0.00387, val loss: 0.00402\n",
      "Interaction training epoch: 140, train loss: 0.00382, val loss: 0.00394\n",
      "Interaction training epoch: 141, train loss: 0.00373, val loss: 0.00391\n",
      "Interaction training epoch: 142, train loss: 0.00371, val loss: 0.00389\n",
      "Interaction training epoch: 143, train loss: 0.00376, val loss: 0.00392\n",
      "Interaction training epoch: 144, train loss: 0.00359, val loss: 0.00386\n",
      "Interaction training epoch: 145, train loss: 0.00361, val loss: 0.00383\n",
      "Interaction training epoch: 146, train loss: 0.00364, val loss: 0.00383\n",
      "Interaction training epoch: 147, train loss: 0.00372, val loss: 0.00385\n",
      "Interaction training epoch: 148, train loss: 0.00357, val loss: 0.00377\n",
      "Interaction training epoch: 149, train loss: 0.00368, val loss: 0.00377\n",
      "Interaction training epoch: 150, train loss: 0.00359, val loss: 0.00375\n",
      "Interaction training epoch: 151, train loss: 0.00352, val loss: 0.00374\n",
      "Interaction training epoch: 152, train loss: 0.00360, val loss: 0.00375\n",
      "Interaction training epoch: 153, train loss: 0.00351, val loss: 0.00369\n",
      "Interaction training epoch: 154, train loss: 0.00343, val loss: 0.00367\n",
      "Interaction training epoch: 155, train loss: 0.00345, val loss: 0.00365\n",
      "Interaction training epoch: 156, train loss: 0.00364, val loss: 0.00374\n",
      "Interaction training epoch: 157, train loss: 0.00342, val loss: 0.00360\n",
      "Interaction training epoch: 158, train loss: 0.00351, val loss: 0.00356\n",
      "Interaction training epoch: 159, train loss: 0.00339, val loss: 0.00356\n",
      "Interaction training epoch: 160, train loss: 0.00334, val loss: 0.00357\n",
      "Interaction training epoch: 161, train loss: 0.00332, val loss: 0.00354\n",
      "Interaction training epoch: 162, train loss: 0.00330, val loss: 0.00347\n",
      "Interaction training epoch: 163, train loss: 0.00327, val loss: 0.00346\n",
      "Interaction training epoch: 164, train loss: 0.00325, val loss: 0.00345\n",
      "Interaction training epoch: 165, train loss: 0.00325, val loss: 0.00348\n",
      "Interaction training epoch: 166, train loss: 0.00326, val loss: 0.00338\n",
      "Interaction training epoch: 167, train loss: 0.00328, val loss: 0.00350\n",
      "Interaction training epoch: 168, train loss: 0.00319, val loss: 0.00335\n",
      "Interaction training epoch: 169, train loss: 0.00317, val loss: 0.00336\n",
      "Interaction training epoch: 170, train loss: 0.00310, val loss: 0.00330\n",
      "Interaction training epoch: 171, train loss: 0.00299, val loss: 0.00327\n",
      "Interaction training epoch: 172, train loss: 0.00307, val loss: 0.00328\n",
      "Interaction training epoch: 173, train loss: 0.00310, val loss: 0.00336\n",
      "Interaction training epoch: 174, train loss: 0.00315, val loss: 0.00336\n",
      "Interaction training epoch: 175, train loss: 0.00303, val loss: 0.00328\n",
      "Interaction training epoch: 176, train loss: 0.00301, val loss: 0.00323\n",
      "Interaction training epoch: 177, train loss: 0.00309, val loss: 0.00329\n",
      "Interaction training epoch: 178, train loss: 0.00293, val loss: 0.00314\n",
      "Interaction training epoch: 179, train loss: 0.00288, val loss: 0.00313\n",
      "Interaction training epoch: 180, train loss: 0.00294, val loss: 0.00312\n",
      "Interaction training epoch: 181, train loss: 0.00286, val loss: 0.00310\n",
      "Interaction training epoch: 182, train loss: 0.00293, val loss: 0.00311\n",
      "Interaction training epoch: 183, train loss: 0.00289, val loss: 0.00305\n",
      "Interaction training epoch: 184, train loss: 0.00279, val loss: 0.00305\n",
      "Interaction training epoch: 185, train loss: 0.00285, val loss: 0.00309\n",
      "Interaction training epoch: 186, train loss: 0.00286, val loss: 0.00305\n",
      "Interaction training epoch: 187, train loss: 0.00282, val loss: 0.00299\n",
      "Interaction training epoch: 188, train loss: 0.00279, val loss: 0.00301\n",
      "Interaction training epoch: 189, train loss: 0.00277, val loss: 0.00296\n",
      "Interaction training epoch: 190, train loss: 0.00287, val loss: 0.00313\n",
      "Interaction training epoch: 191, train loss: 0.00282, val loss: 0.00306\n",
      "Interaction training epoch: 192, train loss: 0.00276, val loss: 0.00297\n",
      "Interaction training epoch: 193, train loss: 0.00269, val loss: 0.00287\n",
      "Interaction training epoch: 194, train loss: 0.00279, val loss: 0.00294\n",
      "Interaction training epoch: 195, train loss: 0.00266, val loss: 0.00294\n",
      "Interaction training epoch: 196, train loss: 0.00273, val loss: 0.00291\n",
      "Interaction training epoch: 197, train loss: 0.00277, val loss: 0.00295\n",
      "Interaction training epoch: 198, train loss: 0.00276, val loss: 0.00295\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interaction training epoch: 199, train loss: 0.00263, val loss: 0.00282\n",
      "Interaction training epoch: 200, train loss: 0.00263, val loss: 0.00289\n",
      "Interaction training epoch: 201, train loss: 0.00258, val loss: 0.00288\n",
      "Interaction training epoch: 202, train loss: 0.00265, val loss: 0.00285\n",
      "Interaction training epoch: 203, train loss: 0.00261, val loss: 0.00281\n",
      "Interaction training epoch: 204, train loss: 0.00258, val loss: 0.00276\n",
      "Interaction training epoch: 205, train loss: 0.00260, val loss: 0.00279\n",
      "Interaction training epoch: 206, train loss: 0.00259, val loss: 0.00277\n",
      "Interaction training epoch: 207, train loss: 0.00272, val loss: 0.00294\n",
      "Interaction training epoch: 208, train loss: 0.00252, val loss: 0.00272\n",
      "Interaction training epoch: 209, train loss: 0.00258, val loss: 0.00276\n",
      "Interaction training epoch: 210, train loss: 0.00262, val loss: 0.00274\n",
      "Interaction training epoch: 211, train loss: 0.00247, val loss: 0.00277\n",
      "Interaction training epoch: 212, train loss: 0.00256, val loss: 0.00276\n",
      "Interaction training epoch: 213, train loss: 0.00255, val loss: 0.00285\n",
      "Interaction training epoch: 214, train loss: 0.00249, val loss: 0.00270\n",
      "Interaction training epoch: 215, train loss: 0.00247, val loss: 0.00277\n",
      "Interaction training epoch: 216, train loss: 0.00265, val loss: 0.00279\n",
      "Interaction training epoch: 217, train loss: 0.00255, val loss: 0.00272\n",
      "Interaction training epoch: 218, train loss: 0.00250, val loss: 0.00271\n",
      "Interaction training epoch: 219, train loss: 0.00251, val loss: 0.00273\n",
      "Interaction training epoch: 220, train loss: 0.00249, val loss: 0.00272\n",
      "Interaction training epoch: 221, train loss: 0.00252, val loss: 0.00273\n",
      "Interaction training epoch: 222, train loss: 0.00254, val loss: 0.00272\n",
      "Interaction training epoch: 223, train loss: 0.00244, val loss: 0.00267\n",
      "Interaction training epoch: 224, train loss: 0.00241, val loss: 0.00265\n",
      "Interaction training epoch: 225, train loss: 0.00240, val loss: 0.00267\n",
      "Interaction training epoch: 226, train loss: 0.00248, val loss: 0.00270\n",
      "Interaction training epoch: 227, train loss: 0.00252, val loss: 0.00270\n",
      "Interaction training epoch: 228, train loss: 0.00241, val loss: 0.00264\n",
      "Interaction training epoch: 229, train loss: 0.00246, val loss: 0.00264\n",
      "Interaction training epoch: 230, train loss: 0.00243, val loss: 0.00263\n",
      "Interaction training epoch: 231, train loss: 0.00241, val loss: 0.00260\n",
      "Interaction training epoch: 232, train loss: 0.00248, val loss: 0.00261\n",
      "Interaction training epoch: 233, train loss: 0.00239, val loss: 0.00259\n",
      "Interaction training epoch: 234, train loss: 0.00241, val loss: 0.00264\n",
      "Interaction training epoch: 235, train loss: 0.00244, val loss: 0.00261\n",
      "Interaction training epoch: 236, train loss: 0.00236, val loss: 0.00262\n",
      "Interaction training epoch: 237, train loss: 0.00242, val loss: 0.00261\n",
      "Interaction training epoch: 238, train loss: 0.00244, val loss: 0.00265\n",
      "Interaction training epoch: 239, train loss: 0.00237, val loss: 0.00261\n",
      "Interaction training epoch: 240, train loss: 0.00232, val loss: 0.00259\n",
      "Interaction training epoch: 241, train loss: 0.00234, val loss: 0.00257\n",
      "Interaction training epoch: 242, train loss: 0.00236, val loss: 0.00259\n",
      "Interaction training epoch: 243, train loss: 0.00244, val loss: 0.00268\n",
      "Interaction training epoch: 244, train loss: 0.00232, val loss: 0.00252\n",
      "Interaction training epoch: 245, train loss: 0.00238, val loss: 0.00256\n",
      "Interaction training epoch: 246, train loss: 0.00238, val loss: 0.00259\n",
      "Interaction training epoch: 247, train loss: 0.00236, val loss: 0.00261\n",
      "Interaction training epoch: 248, train loss: 0.00235, val loss: 0.00252\n",
      "Interaction training epoch: 249, train loss: 0.00234, val loss: 0.00257\n",
      "Interaction training epoch: 250, train loss: 0.00239, val loss: 0.00264\n",
      "Interaction training epoch: 251, train loss: 0.00228, val loss: 0.00256\n",
      "Interaction training epoch: 252, train loss: 0.00235, val loss: 0.00253\n",
      "Interaction training epoch: 253, train loss: 0.00227, val loss: 0.00255\n",
      "Interaction training epoch: 254, train loss: 0.00231, val loss: 0.00252\n",
      "Interaction training epoch: 255, train loss: 0.00232, val loss: 0.00254\n",
      "Interaction training epoch: 256, train loss: 0.00228, val loss: 0.00253\n",
      "Interaction training epoch: 257, train loss: 0.00232, val loss: 0.00256\n",
      "Interaction training epoch: 258, train loss: 0.00228, val loss: 0.00247\n",
      "Interaction training epoch: 259, train loss: 0.00230, val loss: 0.00251\n",
      "Interaction training epoch: 260, train loss: 0.00224, val loss: 0.00248\n",
      "Interaction training epoch: 261, train loss: 0.00231, val loss: 0.00254\n",
      "Interaction training epoch: 262, train loss: 0.00230, val loss: 0.00253\n",
      "Interaction training epoch: 263, train loss: 0.00228, val loss: 0.00257\n",
      "Interaction training epoch: 264, train loss: 0.00230, val loss: 0.00251\n",
      "Interaction training epoch: 265, train loss: 0.00236, val loss: 0.00262\n",
      "Interaction training epoch: 266, train loss: 0.00233, val loss: 0.00249\n",
      "Interaction training epoch: 267, train loss: 0.00239, val loss: 0.00272\n",
      "Interaction training epoch: 268, train loss: 0.00223, val loss: 0.00247\n",
      "Interaction training epoch: 269, train loss: 0.00232, val loss: 0.00256\n",
      "Interaction training epoch: 270, train loss: 0.00231, val loss: 0.00259\n",
      "Interaction training epoch: 271, train loss: 0.00229, val loss: 0.00250\n",
      "Interaction training epoch: 272, train loss: 0.00223, val loss: 0.00249\n",
      "Interaction training epoch: 273, train loss: 0.00222, val loss: 0.00251\n",
      "Interaction training epoch: 274, train loss: 0.00224, val loss: 0.00248\n",
      "Interaction training epoch: 275, train loss: 0.00231, val loss: 0.00257\n",
      "Interaction training epoch: 276, train loss: 0.00245, val loss: 0.00263\n",
      "Interaction training epoch: 277, train loss: 0.00228, val loss: 0.00254\n",
      "Interaction training epoch: 278, train loss: 0.00226, val loss: 0.00255\n",
      "Interaction training epoch: 279, train loss: 0.00228, val loss: 0.00257\n",
      "Interaction training epoch: 280, train loss: 0.00219, val loss: 0.00253\n",
      "Interaction training epoch: 281, train loss: 0.00223, val loss: 0.00248\n",
      "Interaction training epoch: 282, train loss: 0.00235, val loss: 0.00258\n",
      "Interaction training epoch: 283, train loss: 0.00235, val loss: 0.00260\n",
      "Interaction training epoch: 284, train loss: 0.00231, val loss: 0.00262\n",
      "Interaction training epoch: 285, train loss: 0.00226, val loss: 0.00251\n",
      "Interaction training epoch: 286, train loss: 0.00223, val loss: 0.00247\n",
      "Interaction training epoch: 287, train loss: 0.00219, val loss: 0.00245\n",
      "Interaction training epoch: 288, train loss: 0.00222, val loss: 0.00247\n",
      "Interaction training epoch: 289, train loss: 0.00226, val loss: 0.00257\n",
      "Interaction training epoch: 290, train loss: 0.00221, val loss: 0.00246\n",
      "Interaction training epoch: 291, train loss: 0.00236, val loss: 0.00257\n",
      "Interaction training epoch: 292, train loss: 0.00222, val loss: 0.00245\n",
      "Interaction training epoch: 293, train loss: 0.00230, val loss: 0.00260\n",
      "Interaction training epoch: 294, train loss: 0.00224, val loss: 0.00254\n",
      "Interaction training epoch: 295, train loss: 0.00223, val loss: 0.00244\n",
      "Interaction training epoch: 296, train loss: 0.00226, val loss: 0.00255\n",
      "Interaction training epoch: 297, train loss: 0.00238, val loss: 0.00262\n",
      "Interaction training epoch: 298, train loss: 0.00224, val loss: 0.00250\n",
      "Interaction training epoch: 299, train loss: 0.00221, val loss: 0.00251\n",
      "Interaction training epoch: 300, train loss: 0.00213, val loss: 0.00245\n",
      "Interaction training epoch: 301, train loss: 0.00227, val loss: 0.00254\n",
      "Interaction training epoch: 302, train loss: 0.00216, val loss: 0.00242\n",
      "Interaction training epoch: 303, train loss: 0.00213, val loss: 0.00241\n",
      "Interaction training epoch: 304, train loss: 0.00221, val loss: 0.00243\n",
      "Interaction training epoch: 305, train loss: 0.00227, val loss: 0.00246\n",
      "Interaction training epoch: 306, train loss: 0.00217, val loss: 0.00245\n",
      "Interaction training epoch: 307, train loss: 0.00214, val loss: 0.00245\n",
      "Interaction training epoch: 308, train loss: 0.00222, val loss: 0.00249\n",
      "Interaction training epoch: 309, train loss: 0.00216, val loss: 0.00244\n",
      "Interaction training epoch: 310, train loss: 0.00217, val loss: 0.00244\n",
      "Interaction training epoch: 311, train loss: 0.00213, val loss: 0.00236\n",
      "Interaction training epoch: 312, train loss: 0.00213, val loss: 0.00239\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interaction training epoch: 313, train loss: 0.00221, val loss: 0.00249\n",
      "Interaction training epoch: 314, train loss: 0.00217, val loss: 0.00241\n",
      "Interaction training epoch: 315, train loss: 0.00212, val loss: 0.00245\n",
      "Interaction training epoch: 316, train loss: 0.00216, val loss: 0.00243\n",
      "Interaction training epoch: 317, train loss: 0.00217, val loss: 0.00241\n",
      "Interaction training epoch: 318, train loss: 0.00218, val loss: 0.00246\n",
      "Interaction training epoch: 319, train loss: 0.00223, val loss: 0.00246\n",
      "Interaction training epoch: 320, train loss: 0.00223, val loss: 0.00248\n",
      "Interaction training epoch: 321, train loss: 0.00216, val loss: 0.00247\n",
      "Interaction training epoch: 322, train loss: 0.00217, val loss: 0.00244\n",
      "Interaction training epoch: 323, train loss: 0.00214, val loss: 0.00237\n",
      "Interaction training epoch: 324, train loss: 0.00212, val loss: 0.00241\n",
      "Interaction training epoch: 325, train loss: 0.00218, val loss: 0.00242\n",
      "Interaction training epoch: 326, train loss: 0.00214, val loss: 0.00242\n",
      "Interaction training epoch: 327, train loss: 0.00219, val loss: 0.00242\n",
      "Interaction training epoch: 328, train loss: 0.00222, val loss: 0.00248\n",
      "Interaction training epoch: 329, train loss: 0.00220, val loss: 0.00246\n",
      "Interaction training epoch: 330, train loss: 0.00223, val loss: 0.00247\n",
      "Interaction training epoch: 331, train loss: 0.00213, val loss: 0.00244\n",
      "Interaction training epoch: 332, train loss: 0.00209, val loss: 0.00242\n",
      "Interaction training epoch: 333, train loss: 0.00209, val loss: 0.00236\n",
      "Interaction training epoch: 334, train loss: 0.00213, val loss: 0.00238\n",
      "Interaction training epoch: 335, train loss: 0.00215, val loss: 0.00242\n",
      "Interaction training epoch: 336, train loss: 0.00227, val loss: 0.00246\n",
      "Interaction training epoch: 337, train loss: 0.00214, val loss: 0.00242\n",
      "Interaction training epoch: 338, train loss: 0.00206, val loss: 0.00235\n",
      "Interaction training epoch: 339, train loss: 0.00215, val loss: 0.00239\n",
      "Interaction training epoch: 340, train loss: 0.00211, val loss: 0.00240\n",
      "Interaction training epoch: 341, train loss: 0.00213, val loss: 0.00245\n",
      "Interaction training epoch: 342, train loss: 0.00217, val loss: 0.00241\n",
      "Interaction training epoch: 343, train loss: 0.00212, val loss: 0.00239\n",
      "Interaction training epoch: 344, train loss: 0.00216, val loss: 0.00247\n",
      "Interaction training epoch: 345, train loss: 0.00212, val loss: 0.00239\n",
      "Interaction training epoch: 346, train loss: 0.00212, val loss: 0.00244\n",
      "Interaction training epoch: 347, train loss: 0.00214, val loss: 0.00240\n",
      "Interaction training epoch: 348, train loss: 0.00210, val loss: 0.00234\n",
      "Interaction training epoch: 349, train loss: 0.00218, val loss: 0.00249\n",
      "Interaction training epoch: 350, train loss: 0.00209, val loss: 0.00242\n",
      "Interaction training epoch: 351, train loss: 0.00207, val loss: 0.00238\n",
      "Interaction training epoch: 352, train loss: 0.00212, val loss: 0.00242\n",
      "Interaction training epoch: 353, train loss: 0.00215, val loss: 0.00241\n",
      "Interaction training epoch: 354, train loss: 0.00216, val loss: 0.00244\n",
      "Interaction training epoch: 355, train loss: 0.00208, val loss: 0.00244\n",
      "Interaction training epoch: 356, train loss: 0.00215, val loss: 0.00245\n",
      "Interaction training epoch: 357, train loss: 0.00212, val loss: 0.00240\n",
      "Interaction training epoch: 358, train loss: 0.00211, val loss: 0.00243\n",
      "Interaction training epoch: 359, train loss: 0.00215, val loss: 0.00244\n",
      "Interaction training epoch: 360, train loss: 0.00210, val loss: 0.00240\n",
      "Interaction training epoch: 361, train loss: 0.00207, val loss: 0.00234\n",
      "Interaction training epoch: 362, train loss: 0.00208, val loss: 0.00236\n",
      "Interaction training epoch: 363, train loss: 0.00213, val loss: 0.00237\n",
      "Interaction training epoch: 364, train loss: 0.00214, val loss: 0.00244\n",
      "Interaction training epoch: 365, train loss: 0.00210, val loss: 0.00243\n",
      "Interaction training epoch: 366, train loss: 0.00216, val loss: 0.00250\n",
      "Interaction training epoch: 367, train loss: 0.00203, val loss: 0.00241\n",
      "Interaction training epoch: 368, train loss: 0.00206, val loss: 0.00235\n",
      "Interaction training epoch: 369, train loss: 0.00208, val loss: 0.00241\n",
      "Interaction training epoch: 370, train loss: 0.00206, val loss: 0.00237\n",
      "Interaction training epoch: 371, train loss: 0.00209, val loss: 0.00241\n",
      "Interaction training epoch: 372, train loss: 0.00213, val loss: 0.00237\n",
      "Interaction training epoch: 373, train loss: 0.00217, val loss: 0.00248\n",
      "Interaction training epoch: 374, train loss: 0.00213, val loss: 0.00247\n",
      "Interaction training epoch: 375, train loss: 0.00210, val loss: 0.00237\n",
      "Interaction training epoch: 376, train loss: 0.00206, val loss: 0.00241\n",
      "Interaction training epoch: 377, train loss: 0.00211, val loss: 0.00239\n",
      "Interaction training epoch: 378, train loss: 0.00227, val loss: 0.00249\n",
      "Interaction training epoch: 379, train loss: 0.00214, val loss: 0.00242\n",
      "Interaction training epoch: 380, train loss: 0.00212, val loss: 0.00240\n",
      "Interaction training epoch: 381, train loss: 0.00205, val loss: 0.00234\n",
      "Interaction training epoch: 382, train loss: 0.00218, val loss: 0.00249\n",
      "Interaction training epoch: 383, train loss: 0.00210, val loss: 0.00237\n",
      "Interaction training epoch: 384, train loss: 0.00208, val loss: 0.00240\n",
      "Interaction training epoch: 385, train loss: 0.00204, val loss: 0.00238\n",
      "Interaction training epoch: 386, train loss: 0.00215, val loss: 0.00241\n",
      "Interaction training epoch: 387, train loss: 0.00209, val loss: 0.00240\n",
      "Interaction training epoch: 388, train loss: 0.00210, val loss: 0.00243\n",
      "Interaction training epoch: 389, train loss: 0.00214, val loss: 0.00242\n",
      "Interaction training epoch: 390, train loss: 0.00203, val loss: 0.00234\n",
      "Interaction training epoch: 391, train loss: 0.00207, val loss: 0.00234\n",
      "Interaction training epoch: 392, train loss: 0.00209, val loss: 0.00239\n",
      "Interaction training epoch: 393, train loss: 0.00210, val loss: 0.00240\n",
      "Interaction training epoch: 394, train loss: 0.00205, val loss: 0.00234\n",
      "Interaction training epoch: 395, train loss: 0.00209, val loss: 0.00237\n",
      "Interaction training epoch: 396, train loss: 0.00203, val loss: 0.00235\n",
      "Interaction training epoch: 397, train loss: 0.00209, val loss: 0.00234\n",
      "Interaction training epoch: 398, train loss: 0.00205, val loss: 0.00231\n",
      "Interaction training epoch: 399, train loss: 0.00208, val loss: 0.00239\n",
      "Interaction training epoch: 400, train loss: 0.00203, val loss: 0.00239\n",
      "Interaction training epoch: 401, train loss: 0.00202, val loss: 0.00235\n",
      "Interaction training epoch: 402, train loss: 0.00208, val loss: 0.00236\n",
      "Interaction training epoch: 403, train loss: 0.00212, val loss: 0.00241\n",
      "Interaction training epoch: 404, train loss: 0.00205, val loss: 0.00237\n",
      "Interaction training epoch: 405, train loss: 0.00208, val loss: 0.00239\n",
      "Interaction training epoch: 406, train loss: 0.00202, val loss: 0.00232\n",
      "Interaction training epoch: 407, train loss: 0.00207, val loss: 0.00237\n",
      "Interaction training epoch: 408, train loss: 0.00203, val loss: 0.00232\n",
      "Interaction training epoch: 409, train loss: 0.00210, val loss: 0.00245\n",
      "Interaction training epoch: 410, train loss: 0.00203, val loss: 0.00233\n",
      "Interaction training epoch: 411, train loss: 0.00207, val loss: 0.00238\n",
      "Interaction training epoch: 412, train loss: 0.00207, val loss: 0.00237\n",
      "Interaction training epoch: 413, train loss: 0.00202, val loss: 0.00234\n",
      "Interaction training epoch: 414, train loss: 0.00206, val loss: 0.00237\n",
      "Interaction training epoch: 415, train loss: 0.00216, val loss: 0.00254\n",
      "Interaction training epoch: 416, train loss: 0.00202, val loss: 0.00232\n",
      "Interaction training epoch: 417, train loss: 0.00209, val loss: 0.00233\n",
      "Interaction training epoch: 418, train loss: 0.00205, val loss: 0.00234\n",
      "Interaction training epoch: 419, train loss: 0.00205, val loss: 0.00237\n",
      "Interaction training epoch: 420, train loss: 0.00216, val loss: 0.00247\n",
      "Interaction training epoch: 421, train loss: 0.00200, val loss: 0.00236\n",
      "Interaction training epoch: 422, train loss: 0.00203, val loss: 0.00235\n",
      "Interaction training epoch: 423, train loss: 0.00205, val loss: 0.00240\n",
      "Interaction training epoch: 424, train loss: 0.00214, val loss: 0.00242\n",
      "Interaction training epoch: 425, train loss: 0.00206, val loss: 0.00238\n",
      "Interaction training epoch: 426, train loss: 0.00206, val loss: 0.00239\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interaction training epoch: 427, train loss: 0.00204, val loss: 0.00233\n",
      "Interaction training epoch: 428, train loss: 0.00202, val loss: 0.00231\n",
      "Interaction training epoch: 429, train loss: 0.00203, val loss: 0.00236\n",
      "Interaction training epoch: 430, train loss: 0.00203, val loss: 0.00238\n",
      "Interaction training epoch: 431, train loss: 0.00209, val loss: 0.00236\n",
      "Interaction training epoch: 432, train loss: 0.00200, val loss: 0.00232\n",
      "Interaction training epoch: 433, train loss: 0.00200, val loss: 0.00232\n",
      "Interaction training epoch: 434, train loss: 0.00201, val loss: 0.00232\n",
      "Interaction training epoch: 435, train loss: 0.00201, val loss: 0.00237\n",
      "Interaction training epoch: 436, train loss: 0.00206, val loss: 0.00238\n",
      "Interaction training epoch: 437, train loss: 0.00204, val loss: 0.00236\n",
      "Interaction training epoch: 438, train loss: 0.00204, val loss: 0.00241\n",
      "Interaction training epoch: 439, train loss: 0.00203, val loss: 0.00239\n",
      "Interaction training epoch: 440, train loss: 0.00205, val loss: 0.00240\n",
      "Interaction training epoch: 441, train loss: 0.00204, val loss: 0.00236\n",
      "Interaction training epoch: 442, train loss: 0.00208, val loss: 0.00240\n",
      "Interaction training epoch: 443, train loss: 0.00201, val loss: 0.00236\n",
      "Interaction training epoch: 444, train loss: 0.00202, val loss: 0.00238\n",
      "Interaction training epoch: 445, train loss: 0.00211, val loss: 0.00243\n",
      "Interaction training epoch: 446, train loss: 0.00207, val loss: 0.00244\n",
      "Interaction training epoch: 447, train loss: 0.00200, val loss: 0.00232\n",
      "Interaction training epoch: 448, train loss: 0.00206, val loss: 0.00236\n",
      "Interaction training epoch: 449, train loss: 0.00208, val loss: 0.00241\n",
      "Interaction training epoch: 450, train loss: 0.00209, val loss: 0.00249\n",
      "Interaction training epoch: 451, train loss: 0.00203, val loss: 0.00233\n",
      "Interaction training epoch: 452, train loss: 0.00207, val loss: 0.00235\n",
      "Interaction training epoch: 453, train loss: 0.00202, val loss: 0.00236\n",
      "Interaction training epoch: 454, train loss: 0.00206, val loss: 0.00241\n",
      "Interaction training epoch: 455, train loss: 0.00207, val loss: 0.00238\n",
      "Interaction training epoch: 456, train loss: 0.00201, val loss: 0.00232\n",
      "Interaction training epoch: 457, train loss: 0.00201, val loss: 0.00234\n",
      "Interaction training epoch: 458, train loss: 0.00203, val loss: 0.00237\n",
      "Interaction training epoch: 459, train loss: 0.00202, val loss: 0.00240\n",
      "Interaction training epoch: 460, train loss: 0.00205, val loss: 0.00236\n",
      "Interaction training epoch: 461, train loss: 0.00200, val loss: 0.00234\n",
      "Interaction training epoch: 462, train loss: 0.00207, val loss: 0.00236\n",
      "Interaction training epoch: 463, train loss: 0.00205, val loss: 0.00237\n",
      "Interaction training epoch: 464, train loss: 0.00203, val loss: 0.00235\n",
      "Interaction training epoch: 465, train loss: 0.00206, val loss: 0.00240\n",
      "Interaction training epoch: 466, train loss: 0.00217, val loss: 0.00246\n",
      "Interaction training epoch: 467, train loss: 0.00199, val loss: 0.00233\n",
      "Interaction training epoch: 468, train loss: 0.00201, val loss: 0.00239\n",
      "Interaction training epoch: 469, train loss: 0.00202, val loss: 0.00233\n",
      "Interaction training epoch: 470, train loss: 0.00207, val loss: 0.00244\n",
      "Interaction training epoch: 471, train loss: 0.00210, val loss: 0.00240\n",
      "Interaction training epoch: 472, train loss: 0.00200, val loss: 0.00234\n",
      "Interaction training epoch: 473, train loss: 0.00206, val loss: 0.00243\n",
      "Interaction training epoch: 474, train loss: 0.00203, val loss: 0.00241\n",
      "Interaction training epoch: 475, train loss: 0.00218, val loss: 0.00252\n",
      "Interaction training epoch: 476, train loss: 0.00198, val loss: 0.00238\n",
      "Interaction training epoch: 477, train loss: 0.00204, val loss: 0.00238\n",
      "Interaction training epoch: 478, train loss: 0.00205, val loss: 0.00244\n",
      "Interaction training epoch: 479, train loss: 0.00207, val loss: 0.00241\n",
      "Early stop at epoch 479, with validation loss: 0.00241\n",
      "##########Stage 2: interaction training stop.##########\n",
      "Fine tuning epoch: 1, train loss: 0.00204, val loss: 0.00222\n",
      "Fine tuning epoch: 2, train loss: 0.00222, val loss: 0.00231\n",
      "Fine tuning epoch: 3, train loss: 0.00219, val loss: 0.00230\n",
      "Fine tuning epoch: 4, train loss: 0.00213, val loss: 0.00226\n",
      "Fine tuning epoch: 5, train loss: 0.00224, val loss: 0.00239\n",
      "Fine tuning epoch: 6, train loss: 0.00216, val loss: 0.00223\n",
      "Fine tuning epoch: 7, train loss: 0.00214, val loss: 0.00229\n",
      "Fine tuning epoch: 8, train loss: 0.00216, val loss: 0.00226\n",
      "Fine tuning epoch: 9, train loss: 0.00216, val loss: 0.00225\n",
      "Fine tuning epoch: 10, train loss: 0.00218, val loss: 0.00231\n",
      "Fine tuning epoch: 11, train loss: 0.00220, val loss: 0.00227\n",
      "Fine tuning epoch: 12, train loss: 0.00220, val loss: 0.00230\n",
      "Fine tuning epoch: 13, train loss: 0.00214, val loss: 0.00222\n",
      "Fine tuning epoch: 14, train loss: 0.00217, val loss: 0.00233\n",
      "Fine tuning epoch: 15, train loss: 0.00213, val loss: 0.00227\n",
      "Fine tuning epoch: 16, train loss: 0.00213, val loss: 0.00225\n",
      "Fine tuning epoch: 17, train loss: 0.00221, val loss: 0.00232\n",
      "Fine tuning epoch: 18, train loss: 0.00216, val loss: 0.00231\n",
      "Fine tuning epoch: 19, train loss: 0.00208, val loss: 0.00222\n",
      "Fine tuning epoch: 20, train loss: 0.00216, val loss: 0.00234\n",
      "Fine tuning epoch: 21, train loss: 0.00216, val loss: 0.00231\n",
      "Fine tuning epoch: 22, train loss: 0.00215, val loss: 0.00223\n",
      "Fine tuning epoch: 23, train loss: 0.00213, val loss: 0.00231\n",
      "Fine tuning epoch: 24, train loss: 0.00217, val loss: 0.00231\n",
      "Fine tuning epoch: 25, train loss: 0.00209, val loss: 0.00221\n",
      "Fine tuning epoch: 26, train loss: 0.00209, val loss: 0.00224\n",
      "Fine tuning epoch: 27, train loss: 0.00224, val loss: 0.00232\n",
      "Fine tuning epoch: 28, train loss: 0.00211, val loss: 0.00222\n",
      "Fine tuning epoch: 29, train loss: 0.00214, val loss: 0.00228\n",
      "Fine tuning epoch: 30, train loss: 0.00209, val loss: 0.00222\n",
      "Fine tuning epoch: 31, train loss: 0.00220, val loss: 0.00233\n",
      "Fine tuning epoch: 32, train loss: 0.00214, val loss: 0.00225\n",
      "Fine tuning epoch: 33, train loss: 0.00218, val loss: 0.00232\n",
      "Fine tuning epoch: 34, train loss: 0.00215, val loss: 0.00232\n",
      "Fine tuning epoch: 35, train loss: 0.00212, val loss: 0.00225\n",
      "Fine tuning epoch: 36, train loss: 0.00210, val loss: 0.00226\n",
      "Fine tuning epoch: 37, train loss: 0.00211, val loss: 0.00223\n",
      "Fine tuning epoch: 38, train loss: 0.00207, val loss: 0.00221\n",
      "Fine tuning epoch: 39, train loss: 0.00215, val loss: 0.00227\n",
      "Fine tuning epoch: 40, train loss: 0.00211, val loss: 0.00227\n",
      "Fine tuning epoch: 41, train loss: 0.00210, val loss: 0.00224\n",
      "Fine tuning epoch: 42, train loss: 0.00215, val loss: 0.00226\n",
      "Fine tuning epoch: 43, train loss: 0.00214, val loss: 0.00222\n",
      "Fine tuning epoch: 44, train loss: 0.00211, val loss: 0.00225\n",
      "Fine tuning epoch: 45, train loss: 0.00218, val loss: 0.00228\n",
      "Fine tuning epoch: 46, train loss: 0.00211, val loss: 0.00224\n",
      "Fine tuning epoch: 47, train loss: 0.00213, val loss: 0.00231\n",
      "Fine tuning epoch: 48, train loss: 0.00216, val loss: 0.00229\n",
      "Fine tuning epoch: 49, train loss: 0.00212, val loss: 0.00226\n",
      "Fine tuning epoch: 50, train loss: 0.00210, val loss: 0.00228\n",
      "Fine tuning epoch: 51, train loss: 0.00211, val loss: 0.00220\n",
      "Fine tuning epoch: 52, train loss: 0.00218, val loss: 0.00232\n",
      "Fine tuning epoch: 53, train loss: 0.00209, val loss: 0.00223\n",
      "Fine tuning epoch: 54, train loss: 0.00212, val loss: 0.00226\n",
      "Fine tuning epoch: 55, train loss: 0.00219, val loss: 0.00233\n",
      "Fine tuning epoch: 56, train loss: 0.00203, val loss: 0.00221\n",
      "Fine tuning epoch: 57, train loss: 0.00211, val loss: 0.00226\n",
      "Fine tuning epoch: 58, train loss: 0.00210, val loss: 0.00223\n",
      "Fine tuning epoch: 59, train loss: 0.00213, val loss: 0.00221\n",
      "Fine tuning epoch: 60, train loss: 0.00212, val loss: 0.00221\n",
      "Fine tuning epoch: 61, train loss: 0.00216, val loss: 0.00229\n",
      "Fine tuning epoch: 62, train loss: 0.00211, val loss: 0.00222\n",
      "Fine tuning epoch: 63, train loss: 0.00216, val loss: 0.00221\n",
      "Fine tuning epoch: 64, train loss: 0.00208, val loss: 0.00224\n",
      "Fine tuning epoch: 65, train loss: 0.00207, val loss: 0.00222\n",
      "Fine tuning epoch: 66, train loss: 0.00208, val loss: 0.00222\n",
      "Fine tuning epoch: 67, train loss: 0.00218, val loss: 0.00228\n",
      "Fine tuning epoch: 68, train loss: 0.00230, val loss: 0.00240\n",
      "Fine tuning epoch: 69, train loss: 0.00209, val loss: 0.00222\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine tuning epoch: 70, train loss: 0.00207, val loss: 0.00220\n",
      "Fine tuning epoch: 71, train loss: 0.00217, val loss: 0.00234\n",
      "Fine tuning epoch: 72, train loss: 0.00210, val loss: 0.00219\n",
      "Fine tuning epoch: 73, train loss: 0.00209, val loss: 0.00223\n",
      "Fine tuning epoch: 74, train loss: 0.00213, val loss: 0.00225\n",
      "Fine tuning epoch: 75, train loss: 0.00210, val loss: 0.00223\n",
      "Fine tuning epoch: 76, train loss: 0.00209, val loss: 0.00224\n",
      "Fine tuning epoch: 77, train loss: 0.00219, val loss: 0.00226\n",
      "Fine tuning epoch: 78, train loss: 0.00210, val loss: 0.00227\n",
      "Fine tuning epoch: 79, train loss: 0.00209, val loss: 0.00225\n",
      "Fine tuning epoch: 80, train loss: 0.00211, val loss: 0.00225\n",
      "Fine tuning epoch: 81, train loss: 0.00208, val loss: 0.00224\n",
      "Fine tuning epoch: 82, train loss: 0.00211, val loss: 0.00224\n",
      "Fine tuning epoch: 83, train loss: 0.00216, val loss: 0.00229\n",
      "Fine tuning epoch: 84, train loss: 0.00221, val loss: 0.00230\n",
      "Fine tuning epoch: 85, train loss: 0.00209, val loss: 0.00220\n",
      "Fine tuning epoch: 86, train loss: 0.00208, val loss: 0.00225\n",
      "Fine tuning epoch: 87, train loss: 0.00216, val loss: 0.00229\n",
      "Fine tuning epoch: 88, train loss: 0.00206, val loss: 0.00225\n",
      "Fine tuning epoch: 89, train loss: 0.00207, val loss: 0.00220\n",
      "Fine tuning epoch: 90, train loss: 0.00211, val loss: 0.00225\n",
      "Fine tuning epoch: 91, train loss: 0.00209, val loss: 0.00220\n",
      "Fine tuning epoch: 92, train loss: 0.00210, val loss: 0.00223\n",
      "Fine tuning epoch: 93, train loss: 0.00210, val loss: 0.00225\n",
      "Fine tuning epoch: 94, train loss: 0.00213, val loss: 0.00222\n",
      "Fine tuning epoch: 95, train loss: 0.00213, val loss: 0.00230\n",
      "Fine tuning epoch: 96, train loss: 0.00222, val loss: 0.00243\n",
      "Fine tuning epoch: 97, train loss: 0.00204, val loss: 0.00223\n",
      "Fine tuning epoch: 98, train loss: 0.00213, val loss: 0.00227\n",
      "Fine tuning epoch: 99, train loss: 0.00207, val loss: 0.00221\n",
      "Fine tuning epoch: 100, train loss: 0.00213, val loss: 0.00226\n",
      "Fine tuning epoch: 101, train loss: 0.00211, val loss: 0.00227\n",
      "Fine tuning epoch: 102, train loss: 0.00212, val loss: 0.00227\n",
      "Fine tuning epoch: 103, train loss: 0.00214, val loss: 0.00234\n",
      "Fine tuning epoch: 104, train loss: 0.00220, val loss: 0.00228\n",
      "Fine tuning epoch: 105, train loss: 0.00214, val loss: 0.00229\n",
      "Fine tuning epoch: 106, train loss: 0.00204, val loss: 0.00228\n",
      "Fine tuning epoch: 107, train loss: 0.00208, val loss: 0.00221\n",
      "Fine tuning epoch: 108, train loss: 0.00208, val loss: 0.00223\n",
      "Fine tuning epoch: 109, train loss: 0.00210, val loss: 0.00222\n",
      "Fine tuning epoch: 110, train loss: 0.00218, val loss: 0.00233\n",
      "Fine tuning epoch: 111, train loss: 0.00210, val loss: 0.00227\n",
      "Fine tuning epoch: 112, train loss: 0.00212, val loss: 0.00222\n",
      "Fine tuning epoch: 113, train loss: 0.00214, val loss: 0.00229\n",
      "Fine tuning epoch: 114, train loss: 0.00219, val loss: 0.00235\n",
      "Fine tuning epoch: 115, train loss: 0.00210, val loss: 0.00222\n",
      "Fine tuning epoch: 116, train loss: 0.00209, val loss: 0.00226\n",
      "Fine tuning epoch: 117, train loss: 0.00212, val loss: 0.00228\n",
      "Fine tuning epoch: 118, train loss: 0.00212, val loss: 0.00223\n",
      "Fine tuning epoch: 119, train loss: 0.00213, val loss: 0.00227\n",
      "Fine tuning epoch: 120, train loss: 0.00208, val loss: 0.00220\n",
      "Fine tuning epoch: 121, train loss: 0.00206, val loss: 0.00221\n",
      "Fine tuning epoch: 122, train loss: 0.00205, val loss: 0.00223\n",
      "Fine tuning epoch: 123, train loss: 0.00207, val loss: 0.00226\n",
      "Early stop at epoch 123, with validation loss: 0.00226\n",
      "####################GAMI-Net training finished.####################\n"
     ]
    }
   ],
   "source": [
    "model = GAMINet(meta_info=meta_info, interact_num=20, \n",
    "                interact_arch=[40] * 5, subnet_arch=[40] * 5, \n",
    "                lr_bp=0.0001, batch_size=200, task_type=task_type, activation_func=tf.nn.relu, \n",
    "                main_effect_epochs=500, interaction_epochs=500, tuning_epochs=500, early_stop_thres=50, \n",
    "                heredity=True, loss_threshold=0.01, reg_clarity=1,\n",
    "                verbose=True, val_ratio=0.2, random_state=random_state)\n",
    "model.fit(train_x, train_y, sample_weight=np.random.uniform(0, 1, size=(train_x.shape[0], 1)))\n",
    "\n",
    "val_x = train_x[model.val_idx, :]\n",
    "val_y = train_y[model.val_idx, :]\n",
    "tr_x = train_x[model.tr_idx, :]\n",
    "tr_y = train_y[model.tr_idx, :]\n",
    "pred_train = model.predict(tr_x)\n",
    "pred_val = model.predict(val_x)\n",
    "pred_test = model.predict(test_x)\n",
    "gaminet_stat = np.hstack([np.round(get_metric(tr_y, pred_train),5), \n",
    "                      np.round(get_metric(val_y, pred_val),5),\n",
    "                      np.round(get_metric(test_y, pred_test),5)])\n",
    "print(gaminet_stat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-06-15T07:21:41.735Z"
    }
   },
   "outputs": [],
   "source": [
    "simu_dir = \"./results/\"\n",
    "if not os.path.exists(simu_dir):\n",
    "    os.makedirs(simu_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-06-15T07:21:41.764Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_dict_logs = model.summary_logs(save_dict=False)\n",
    "plot_trajectory(data_dict_logs, folder=simu_dir, name=\"s1_traj_plot\", log_scale=True, save_png=True, save_eps=False)\n",
    "plot_regularization(data_dict_logs, folder=simu_dir, name=\"s1_regu_plot\", log_scale=True, save_png=True, save_eps=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Global Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-06-15T07:21:41.794Z"
    }
   },
   "outputs": [],
   "source": [
    "data_dict_global = model.global_explain(save_dict=False)\n",
    "global_visualize_density(data_dict_global, save_png=True, folder=simu_dir, name='s1_global')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-06-15T07:21:41.819Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feature_importance_visualize(data_dict_global, save_png=True, folder=simu_dir, name='s1_feature')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Local Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-06-15T07:21:41.842Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_dict_local = model.local_explain(train_x[:10], train_y[:10], save_dict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-06-15T07:21:41.852Z"
    }
   },
   "outputs": [],
   "source": [
    "local_visualize(data_dict_local[0], save_png=True, folder=simu_dir, name='s1_local')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-06-15T07:21:41.864Z"
    }
   },
   "outputs": [],
   "source": [
    "local_visualize(data_dict_local[1], save_png=True, folder=simu_dir, name='s1_local')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model save and load "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-06-15T07:21:41.894Z"
    }
   },
   "outputs": [],
   "source": [
    "# model.__call__(np.random.uniform(0, 1, size=(1, len(model.meta_info) - 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-06-15T07:21:41.903Z"
    }
   },
   "outputs": [],
   "source": [
    "model.save(folder=\"./\", name=\"model_saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-06-15T07:21:41.914Z"
    }
   },
   "outputs": [],
   "source": [
    "modelnew = GAMINet(meta_info={})\n",
    "modelnew.load(folder=\"./\", name=\"model_saved\")\n",
    "\n",
    "pred_train = modelnew.predict(tr_x)\n",
    "pred_val = modelnew.predict(val_x)\n",
    "pred_test = modelnew.predict(test_x)\n",
    "gaminet_stat = np.hstack([np.round(get_metric(tr_y, pred_train),5), \n",
    "                      np.round(get_metric(val_y, pred_val),5),\n",
    "                      np.round(get_metric(test_y, pred_test),5)])\n",
    "print(gaminet_stat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
