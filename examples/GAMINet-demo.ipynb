{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from gaminet import GAMINet\n",
    "from gaminet.utils import feature_importance\n",
    "from gaminet.utils import local_visualize\n",
    "from gaminet.utils import global_visualize_density\n",
    "from gaminet.utils import global_visualize_wo_density"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric_wrapper(metric, scaler):\n",
    "    def wrapper(label, pred):\n",
    "        return metric(label, pred, scaler=scaler)\n",
    "    return wrapper\n",
    "\n",
    "def rmse(label, pred, scaler):\n",
    "    pred = scaler.inverse_transform(pred.reshape([-1, 1]))\n",
    "    label = scaler.inverse_transform(label.reshape([-1, 1]))\n",
    "    return np.sqrt(np.mean((pred - label)**2))\n",
    "\n",
    "def data_generator1(datanum, random_state=0):\n",
    "    \n",
    "    np.random.seed(random_state)\n",
    "    x = np.zeros((datanum, 10))\n",
    "    for i in range(10):\n",
    "        x[:, i:i+1] = np.random.uniform(0, 1,[datanum,1])\n",
    "    x1, x2, x3, x4, x5, x6, x7, x8, x9, x10 = [x[:, [i]] for i in range(10)]\n",
    "\n",
    "    def cliff(x1, x2):\n",
    "        # x1: -20,20\n",
    "        # x2: -10,5\n",
    "        x1 = (2 * x1 - 1) * 20\n",
    "        x2 = (2 * x2 - 1) * 7.5 - 2.5\n",
    "        term1 = -0.5 * x1 ** 2 / 100\n",
    "        term2 = -0.5 * (x2 + 0.03 * x1 ** 2 - 3) ** 2\n",
    "        y = 10 * np.exp(term1 + term2)\n",
    "        return  y\n",
    "\n",
    "    y = (8 * (x1 - 0.5) ** 2\n",
    "         + 0.1 * np.exp(-8 * x2 + 4)\n",
    "         + 3 * np.sin(2 * np.pi * x3 * x4)\n",
    "         + cliff(x5, x6)).reshape([-1,1]) + 1 * np.random.normal(0, 1, [datanum, 1])\n",
    "\n",
    "    task_type = \"Regression\"\n",
    "    meta_info = {\"X1\":{\"type\":'continuous'},\n",
    "             'X2':{'type':'continuous'},\n",
    "             'X3':{'type':'continuous'},\n",
    "             'X4':{'type':'continuous'},\n",
    "             'X5':{'type':'continuous'},\n",
    "             'X6':{'type':'continuous'},\n",
    "             'X7':{'type':'continuous'},\n",
    "             'X8':{'type':'continuous'},\n",
    "             'X9':{'type':'continuous'},\n",
    "             'X10':{'type':'continuous'},\n",
    "             'Y':{'type':'target'}}\n",
    "    for i, (key, item) in enumerate(meta_info.items()):\n",
    "        if item['type'] == 'target':\n",
    "            sy = MinMaxScaler((0, 1))\n",
    "            y = sy.fit_transform(y)\n",
    "            meta_info[key]['scaler'] = sy\n",
    "        else:\n",
    "            sx = MinMaxScaler((0, 1))\n",
    "            sx.fit([[0], [1]])\n",
    "            x[:,[i]] = sx.transform(x[:,[i]])\n",
    "            meta_info[key]['scaler'] = sx\n",
    "\n",
    "    train_x, test_x, train_y, test_y = train_test_split(x, y, test_size=0.2, random_state=random_state)\n",
    "    return train_x, test_x, train_y, test_y, task_type, meta_info, metric_wrapper(rmse, sy)\n",
    "\n",
    "train_x, test_x, train_y, test_y, task_type, meta_info, get_metric = data_generator1(datanum=5000, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train GAMI-Net "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main effects training epoch: 1, train loss: 0.13117, val loss: 0.13101\n",
      "Main effects training epoch: 2, train loss: 0.12540, val loss: 0.12523\n",
      "Main effects training epoch: 3, train loss: 0.12052, val loss: 0.12037\n",
      "Main effects training epoch: 4, train loss: 0.11592, val loss: 0.11590\n",
      "Main effects training epoch: 5, train loss: 0.11178, val loss: 0.11174\n",
      "Main effects training epoch: 6, train loss: 0.10781, val loss: 0.10770\n",
      "Main effects training epoch: 7, train loss: 0.10394, val loss: 0.10392\n",
      "Main effects training epoch: 8, train loss: 0.10021, val loss: 0.10031\n",
      "Main effects training epoch: 9, train loss: 0.09677, val loss: 0.09690\n",
      "Main effects training epoch: 10, train loss: 0.09353, val loss: 0.09369\n",
      "Main effects training epoch: 11, train loss: 0.09005, val loss: 0.09022\n",
      "Main effects training epoch: 12, train loss: 0.08719, val loss: 0.08743\n",
      "Main effects training epoch: 13, train loss: 0.08436, val loss: 0.08457\n",
      "Main effects training epoch: 14, train loss: 0.08103, val loss: 0.08112\n",
      "Main effects training epoch: 15, train loss: 0.07821, val loss: 0.07837\n",
      "Main effects training epoch: 16, train loss: 0.07560, val loss: 0.07571\n",
      "Main effects training epoch: 17, train loss: 0.07324, val loss: 0.07336\n",
      "Main effects training epoch: 18, train loss: 0.07066, val loss: 0.07071\n",
      "Main effects training epoch: 19, train loss: 0.06832, val loss: 0.06840\n",
      "Main effects training epoch: 20, train loss: 0.06606, val loss: 0.06619\n",
      "Main effects training epoch: 21, train loss: 0.06375, val loss: 0.06391\n",
      "Main effects training epoch: 22, train loss: 0.06165, val loss: 0.06181\n",
      "Main effects training epoch: 23, train loss: 0.05948, val loss: 0.05964\n",
      "Main effects training epoch: 24, train loss: 0.05713, val loss: 0.05725\n",
      "Main effects training epoch: 25, train loss: 0.05521, val loss: 0.05531\n",
      "Main effects training epoch: 26, train loss: 0.05339, val loss: 0.05350\n",
      "Main effects training epoch: 27, train loss: 0.05166, val loss: 0.05173\n",
      "Main effects training epoch: 28, train loss: 0.04972, val loss: 0.04976\n",
      "Main effects training epoch: 29, train loss: 0.04780, val loss: 0.04790\n",
      "Main effects training epoch: 30, train loss: 0.04617, val loss: 0.04625\n",
      "Main effects training epoch: 31, train loss: 0.04445, val loss: 0.04455\n",
      "Main effects training epoch: 32, train loss: 0.04297, val loss: 0.04310\n",
      "Main effects training epoch: 33, train loss: 0.04127, val loss: 0.04140\n",
      "Main effects training epoch: 34, train loss: 0.04006, val loss: 0.04022\n",
      "Main effects training epoch: 35, train loss: 0.03897, val loss: 0.03915\n",
      "Main effects training epoch: 36, train loss: 0.03767, val loss: 0.03778\n",
      "Main effects training epoch: 37, train loss: 0.03592, val loss: 0.03594\n",
      "Main effects training epoch: 38, train loss: 0.03490, val loss: 0.03509\n",
      "Main effects training epoch: 39, train loss: 0.03370, val loss: 0.03387\n",
      "Main effects training epoch: 40, train loss: 0.03258, val loss: 0.03273\n",
      "Main effects training epoch: 41, train loss: 0.03164, val loss: 0.03181\n",
      "Main effects training epoch: 42, train loss: 0.03053, val loss: 0.03067\n",
      "Main effects training epoch: 43, train loss: 0.02935, val loss: 0.02953\n",
      "Main effects training epoch: 44, train loss: 0.02849, val loss: 0.02870\n",
      "Main effects training epoch: 45, train loss: 0.02761, val loss: 0.02778\n",
      "Main effects training epoch: 46, train loss: 0.02704, val loss: 0.02720\n",
      "Main effects training epoch: 47, train loss: 0.02624, val loss: 0.02643\n",
      "Main effects training epoch: 48, train loss: 0.02523, val loss: 0.02540\n",
      "Main effects training epoch: 49, train loss: 0.02454, val loss: 0.02478\n",
      "Main effects training epoch: 50, train loss: 0.02389, val loss: 0.02410\n",
      "Main effects training epoch: 51, train loss: 0.02329, val loss: 0.02342\n",
      "Main effects training epoch: 52, train loss: 0.02257, val loss: 0.02269\n",
      "Main effects training epoch: 53, train loss: 0.02189, val loss: 0.02212\n",
      "Main effects training epoch: 54, train loss: 0.02133, val loss: 0.02154\n",
      "Main effects training epoch: 55, train loss: 0.02080, val loss: 0.02098\n",
      "Main effects training epoch: 56, train loss: 0.02016, val loss: 0.02034\n",
      "Main effects training epoch: 57, train loss: 0.01955, val loss: 0.01966\n",
      "Main effects training epoch: 58, train loss: 0.01915, val loss: 0.01928\n",
      "Main effects training epoch: 59, train loss: 0.01882, val loss: 0.01899\n",
      "Main effects training epoch: 60, train loss: 0.01822, val loss: 0.01831\n",
      "Main effects training epoch: 61, train loss: 0.01773, val loss: 0.01780\n",
      "Main effects training epoch: 62, train loss: 0.01732, val loss: 0.01738\n",
      "Main effects training epoch: 63, train loss: 0.01711, val loss: 0.01724\n",
      "Main effects training epoch: 64, train loss: 0.01667, val loss: 0.01671\n",
      "Main effects training epoch: 65, train loss: 0.01616, val loss: 0.01620\n",
      "Main effects training epoch: 66, train loss: 0.01577, val loss: 0.01578\n",
      "Main effects training epoch: 67, train loss: 0.01573, val loss: 0.01578\n",
      "Main effects training epoch: 68, train loss: 0.01525, val loss: 0.01523\n",
      "Main effects training epoch: 69, train loss: 0.01488, val loss: 0.01485\n",
      "Main effects training epoch: 70, train loss: 0.01470, val loss: 0.01472\n",
      "Main effects training epoch: 71, train loss: 0.01436, val loss: 0.01435\n",
      "Main effects training epoch: 72, train loss: 0.01392, val loss: 0.01387\n",
      "Main effects training epoch: 73, train loss: 0.01389, val loss: 0.01384\n",
      "Main effects training epoch: 74, train loss: 0.01366, val loss: 0.01357\n",
      "Main effects training epoch: 75, train loss: 0.01334, val loss: 0.01325\n",
      "Main effects training epoch: 76, train loss: 0.01296, val loss: 0.01292\n",
      "Main effects training epoch: 77, train loss: 0.01278, val loss: 0.01270\n",
      "Main effects training epoch: 78, train loss: 0.01278, val loss: 0.01269\n",
      "Main effects training epoch: 79, train loss: 0.01253, val loss: 0.01245\n",
      "Main effects training epoch: 80, train loss: 0.01227, val loss: 0.01214\n",
      "Main effects training epoch: 81, train loss: 0.01219, val loss: 0.01208\n",
      "Main effects training epoch: 82, train loss: 0.01196, val loss: 0.01191\n",
      "Main effects training epoch: 83, train loss: 0.01188, val loss: 0.01176\n",
      "Main effects training epoch: 84, train loss: 0.01178, val loss: 0.01166\n",
      "Main effects training epoch: 85, train loss: 0.01159, val loss: 0.01146\n",
      "Main effects training epoch: 86, train loss: 0.01158, val loss: 0.01149\n",
      "Main effects training epoch: 87, train loss: 0.01134, val loss: 0.01126\n",
      "Main effects training epoch: 88, train loss: 0.01105, val loss: 0.01098\n",
      "Main effects training epoch: 89, train loss: 0.01115, val loss: 0.01102\n",
      "Main effects training epoch: 90, train loss: 0.01105, val loss: 0.01092\n",
      "Main effects training epoch: 91, train loss: 0.01098, val loss: 0.01091\n",
      "Main effects training epoch: 92, train loss: 0.01100, val loss: 0.01093\n",
      "Main effects training epoch: 93, train loss: 0.01085, val loss: 0.01072\n",
      "Main effects training epoch: 94, train loss: 0.01078, val loss: 0.01067\n",
      "Main effects training epoch: 95, train loss: 0.01063, val loss: 0.01051\n",
      "Main effects training epoch: 96, train loss: 0.01049, val loss: 0.01041\n",
      "Main effects training epoch: 97, train loss: 0.01068, val loss: 0.01054\n",
      "Main effects training epoch: 98, train loss: 0.01061, val loss: 0.01050\n",
      "Main effects training epoch: 99, train loss: 0.01035, val loss: 0.01025\n",
      "Main effects training epoch: 100, train loss: 0.01049, val loss: 0.01040\n",
      "Main effects training epoch: 101, train loss: 0.01029, val loss: 0.01015\n",
      "Main effects training epoch: 102, train loss: 0.01040, val loss: 0.01033\n",
      "Main effects training epoch: 103, train loss: 0.01026, val loss: 0.01012\n",
      "Main effects training epoch: 104, train loss: 0.01028, val loss: 0.01017\n",
      "Main effects training epoch: 105, train loss: 0.01024, val loss: 0.01011\n",
      "Main effects training epoch: 106, train loss: 0.01022, val loss: 0.01010\n",
      "Main effects training epoch: 107, train loss: 0.01022, val loss: 0.01011\n",
      "Main effects training epoch: 108, train loss: 0.01017, val loss: 0.01007\n",
      "Main effects training epoch: 109, train loss: 0.01013, val loss: 0.01003\n",
      "Main effects training epoch: 110, train loss: 0.01015, val loss: 0.01005\n",
      "Main effects training epoch: 111, train loss: 0.01010, val loss: 0.00999\n",
      "Main effects training epoch: 112, train loss: 0.01014, val loss: 0.01000\n",
      "Main effects training epoch: 113, train loss: 0.01003, val loss: 0.00992\n",
      "Main effects training epoch: 114, train loss: 0.01008, val loss: 0.01000\n",
      "Main effects training epoch: 115, train loss: 0.01007, val loss: 0.00997\n",
      "Main effects training epoch: 116, train loss: 0.01004, val loss: 0.00991\n",
      "Main effects training epoch: 117, train loss: 0.01002, val loss: 0.00991\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main effects training epoch: 118, train loss: 0.01003, val loss: 0.00996\n",
      "Main effects training epoch: 119, train loss: 0.01001, val loss: 0.00991\n",
      "Main effects training epoch: 120, train loss: 0.00997, val loss: 0.00985\n",
      "Main effects training epoch: 121, train loss: 0.01007, val loss: 0.00998\n",
      "Main effects training epoch: 122, train loss: 0.00998, val loss: 0.00987\n",
      "Main effects training epoch: 123, train loss: 0.00994, val loss: 0.00983\n",
      "Main effects training epoch: 124, train loss: 0.01002, val loss: 0.00993\n",
      "Main effects training epoch: 125, train loss: 0.00996, val loss: 0.00981\n",
      "Main effects training epoch: 126, train loss: 0.00995, val loss: 0.00985\n",
      "Main effects training epoch: 127, train loss: 0.00996, val loss: 0.00987\n",
      "Main effects training epoch: 128, train loss: 0.00994, val loss: 0.00983\n",
      "Main effects training epoch: 129, train loss: 0.00993, val loss: 0.00980\n",
      "Main effects training epoch: 130, train loss: 0.00994, val loss: 0.00982\n",
      "Main effects training epoch: 131, train loss: 0.00995, val loss: 0.00983\n",
      "Main effects training epoch: 132, train loss: 0.00996, val loss: 0.00982\n",
      "Main effects training epoch: 133, train loss: 0.00993, val loss: 0.00984\n",
      "Main effects training epoch: 134, train loss: 0.00993, val loss: 0.00987\n",
      "Main effects training epoch: 135, train loss: 0.00992, val loss: 0.00979\n",
      "Main effects training epoch: 136, train loss: 0.00991, val loss: 0.00976\n",
      "Main effects training epoch: 137, train loss: 0.00993, val loss: 0.00981\n",
      "Main effects training epoch: 138, train loss: 0.00991, val loss: 0.00979\n",
      "Main effects training epoch: 139, train loss: 0.00990, val loss: 0.00975\n",
      "Main effects training epoch: 140, train loss: 0.00990, val loss: 0.00979\n",
      "Main effects training epoch: 141, train loss: 0.00991, val loss: 0.00982\n",
      "Main effects training epoch: 142, train loss: 0.00990, val loss: 0.00974\n",
      "Main effects training epoch: 143, train loss: 0.00992, val loss: 0.00984\n",
      "Main effects training epoch: 144, train loss: 0.00990, val loss: 0.00979\n",
      "Main effects training epoch: 145, train loss: 0.00988, val loss: 0.00976\n",
      "Main effects training epoch: 146, train loss: 0.00989, val loss: 0.00979\n",
      "Main effects training epoch: 147, train loss: 0.00989, val loss: 0.00977\n",
      "Main effects training epoch: 148, train loss: 0.00988, val loss: 0.00981\n",
      "Main effects training epoch: 149, train loss: 0.00990, val loss: 0.00979\n",
      "Main effects training epoch: 150, train loss: 0.00989, val loss: 0.00973\n",
      "Main effects training epoch: 151, train loss: 0.00988, val loss: 0.00978\n",
      "Main effects training epoch: 152, train loss: 0.00988, val loss: 0.00978\n",
      "Main effects training epoch: 153, train loss: 0.00988, val loss: 0.00976\n",
      "Main effects training epoch: 154, train loss: 0.00989, val loss: 0.00980\n",
      "Main effects training epoch: 155, train loss: 0.00989, val loss: 0.00972\n",
      "Main effects training epoch: 156, train loss: 0.00988, val loss: 0.00979\n",
      "Main effects training epoch: 157, train loss: 0.00987, val loss: 0.00976\n",
      "Main effects training epoch: 158, train loss: 0.00988, val loss: 0.00977\n",
      "Main effects training epoch: 159, train loss: 0.00986, val loss: 0.00973\n",
      "Main effects training epoch: 160, train loss: 0.00987, val loss: 0.00972\n",
      "Main effects training epoch: 161, train loss: 0.00988, val loss: 0.00979\n",
      "Main effects training epoch: 162, train loss: 0.00987, val loss: 0.00975\n",
      "Main effects training epoch: 163, train loss: 0.00986, val loss: 0.00971\n",
      "Main effects training epoch: 164, train loss: 0.00986, val loss: 0.00980\n",
      "Main effects training epoch: 165, train loss: 0.00986, val loss: 0.00975\n",
      "Main effects training epoch: 166, train loss: 0.00987, val loss: 0.00974\n",
      "Main effects training epoch: 167, train loss: 0.00987, val loss: 0.00974\n",
      "Main effects training epoch: 168, train loss: 0.00986, val loss: 0.00977\n",
      "Main effects training epoch: 169, train loss: 0.00987, val loss: 0.00977\n",
      "Main effects training epoch: 170, train loss: 0.00986, val loss: 0.00975\n",
      "Main effects training epoch: 171, train loss: 0.00985, val loss: 0.00975\n",
      "Main effects training epoch: 172, train loss: 0.00985, val loss: 0.00969\n",
      "Main effects training epoch: 173, train loss: 0.00985, val loss: 0.00977\n",
      "Main effects training epoch: 174, train loss: 0.00985, val loss: 0.00972\n",
      "Main effects training epoch: 175, train loss: 0.00985, val loss: 0.00971\n",
      "Main effects training epoch: 176, train loss: 0.00985, val loss: 0.00977\n",
      "Main effects training epoch: 177, train loss: 0.00985, val loss: 0.00976\n",
      "Main effects training epoch: 178, train loss: 0.00984, val loss: 0.00974\n",
      "Main effects training epoch: 179, train loss: 0.00985, val loss: 0.00972\n",
      "Main effects training epoch: 180, train loss: 0.00985, val loss: 0.00973\n",
      "Main effects training epoch: 181, train loss: 0.00985, val loss: 0.00979\n",
      "Main effects training epoch: 182, train loss: 0.00985, val loss: 0.00973\n",
      "Main effects training epoch: 183, train loss: 0.00983, val loss: 0.00972\n",
      "Main effects training epoch: 184, train loss: 0.00984, val loss: 0.00978\n",
      "Main effects training epoch: 185, train loss: 0.00984, val loss: 0.00970\n",
      "Main effects training epoch: 186, train loss: 0.00984, val loss: 0.00971\n",
      "Main effects training epoch: 187, train loss: 0.00983, val loss: 0.00975\n",
      "Main effects training epoch: 188, train loss: 0.00983, val loss: 0.00973\n",
      "Main effects training epoch: 189, train loss: 0.00983, val loss: 0.00973\n",
      "Main effects training epoch: 190, train loss: 0.00983, val loss: 0.00973\n",
      "Main effects training epoch: 191, train loss: 0.00983, val loss: 0.00975\n",
      "Main effects training epoch: 192, train loss: 0.00982, val loss: 0.00972\n",
      "Main effects training epoch: 193, train loss: 0.00984, val loss: 0.00975\n",
      "Main effects training epoch: 194, train loss: 0.00984, val loss: 0.00975\n",
      "Main effects training epoch: 195, train loss: 0.00984, val loss: 0.00982\n",
      "Main effects training epoch: 196, train loss: 0.00982, val loss: 0.00972\n",
      "Main effects training epoch: 197, train loss: 0.00982, val loss: 0.00971\n",
      "Main effects training epoch: 198, train loss: 0.00983, val loss: 0.00975\n",
      "Main effects training epoch: 199, train loss: 0.00982, val loss: 0.00971\n",
      "Main effects training epoch: 200, train loss: 0.00984, val loss: 0.00983\n",
      "Main effects training epoch: 201, train loss: 0.00981, val loss: 0.00976\n",
      "Main effects training epoch: 202, train loss: 0.00981, val loss: 0.00969\n",
      "Main effects training epoch: 203, train loss: 0.00981, val loss: 0.00968\n",
      "Main effects training epoch: 204, train loss: 0.00982, val loss: 0.00978\n",
      "Main effects training epoch: 205, train loss: 0.00981, val loss: 0.00974\n",
      "Main effects training epoch: 206, train loss: 0.00980, val loss: 0.00972\n",
      "Main effects training epoch: 207, train loss: 0.00980, val loss: 0.00970\n",
      "Main effects training epoch: 208, train loss: 0.00981, val loss: 0.00980\n",
      "Main effects training epoch: 209, train loss: 0.00980, val loss: 0.00972\n",
      "Main effects training epoch: 210, train loss: 0.00981, val loss: 0.00967\n",
      "Main effects training epoch: 211, train loss: 0.00981, val loss: 0.00980\n",
      "Main effects training epoch: 212, train loss: 0.00980, val loss: 0.00973\n",
      "Main effects training epoch: 213, train loss: 0.00979, val loss: 0.00971\n",
      "Main effects training epoch: 214, train loss: 0.00979, val loss: 0.00973\n",
      "Main effects training epoch: 215, train loss: 0.00978, val loss: 0.00973\n",
      "Main effects training epoch: 216, train loss: 0.00979, val loss: 0.00966\n",
      "Main effects training epoch: 217, train loss: 0.00979, val loss: 0.00971\n",
      "Main effects training epoch: 218, train loss: 0.00978, val loss: 0.00973\n",
      "Main effects training epoch: 219, train loss: 0.00978, val loss: 0.00973\n",
      "Main effects training epoch: 220, train loss: 0.00978, val loss: 0.00966\n",
      "Main effects training epoch: 221, train loss: 0.00977, val loss: 0.00969\n",
      "Main effects training epoch: 222, train loss: 0.00977, val loss: 0.00974\n",
      "Main effects training epoch: 223, train loss: 0.00977, val loss: 0.00976\n",
      "Main effects training epoch: 224, train loss: 0.00977, val loss: 0.00967\n",
      "Main effects training epoch: 225, train loss: 0.00975, val loss: 0.00971\n",
      "Main effects training epoch: 226, train loss: 0.00975, val loss: 0.00971\n",
      "Main effects training epoch: 227, train loss: 0.00975, val loss: 0.00971\n",
      "Main effects training epoch: 228, train loss: 0.00974, val loss: 0.00969\n",
      "Main effects training epoch: 229, train loss: 0.00974, val loss: 0.00972\n",
      "Main effects training epoch: 230, train loss: 0.00974, val loss: 0.00971\n",
      "Main effects training epoch: 231, train loss: 0.00973, val loss: 0.00964\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main effects training epoch: 232, train loss: 0.00973, val loss: 0.00963\n",
      "Main effects training epoch: 233, train loss: 0.00972, val loss: 0.00970\n",
      "Main effects training epoch: 234, train loss: 0.00971, val loss: 0.00971\n",
      "Main effects training epoch: 235, train loss: 0.00971, val loss: 0.00963\n",
      "Main effects training epoch: 236, train loss: 0.00970, val loss: 0.00964\n",
      "Main effects training epoch: 237, train loss: 0.00971, val loss: 0.00966\n",
      "Main effects training epoch: 238, train loss: 0.00970, val loss: 0.00968\n",
      "Main effects training epoch: 239, train loss: 0.00969, val loss: 0.00963\n",
      "Main effects training epoch: 240, train loss: 0.00969, val loss: 0.00963\n",
      "Main effects training epoch: 241, train loss: 0.00968, val loss: 0.00967\n",
      "Main effects training epoch: 242, train loss: 0.00968, val loss: 0.00962\n",
      "Main effects training epoch: 243, train loss: 0.00966, val loss: 0.00961\n",
      "Main effects training epoch: 244, train loss: 0.00966, val loss: 0.00965\n",
      "Main effects training epoch: 245, train loss: 0.00966, val loss: 0.00959\n",
      "Main effects training epoch: 246, train loss: 0.00966, val loss: 0.00958\n",
      "Main effects training epoch: 247, train loss: 0.00965, val loss: 0.00962\n",
      "Main effects training epoch: 248, train loss: 0.00965, val loss: 0.00959\n",
      "Main effects training epoch: 249, train loss: 0.00964, val loss: 0.00961\n",
      "Main effects training epoch: 250, train loss: 0.00964, val loss: 0.00966\n",
      "Main effects training epoch: 251, train loss: 0.00963, val loss: 0.00962\n",
      "Main effects training epoch: 252, train loss: 0.00963, val loss: 0.00956\n",
      "Main effects training epoch: 253, train loss: 0.00962, val loss: 0.00963\n",
      "Main effects training epoch: 254, train loss: 0.00961, val loss: 0.00960\n",
      "Main effects training epoch: 255, train loss: 0.00961, val loss: 0.00956\n",
      "Main effects training epoch: 256, train loss: 0.00961, val loss: 0.00955\n",
      "Main effects training epoch: 257, train loss: 0.00960, val loss: 0.00954\n",
      "Main effects training epoch: 258, train loss: 0.00961, val loss: 0.00962\n",
      "Main effects training epoch: 259, train loss: 0.00960, val loss: 0.00960\n",
      "Main effects training epoch: 260, train loss: 0.00962, val loss: 0.00953\n",
      "Main effects training epoch: 261, train loss: 0.00960, val loss: 0.00957\n"
     ]
    }
   ],
   "source": [
    "model = GAMINet(meta_info=meta_info, interact_num=20, interact_arch=[20, 10],\n",
    "            subnet_arch=[20, 10], task_type=task_type, activation_func=tf.tanh, main_grid_size=41, interact_grid_size=41,\n",
    "            batch_size=min(500, int(0.2*train_x.shape[0])), lr_bp=0.001, main_effect_epochs=2000,\n",
    "            interaction_epochs=2000, tuning_epochs=50, loss_threshold=0.01,\n",
    "            verbose=True, val_ratio=0.2, early_stop_thres=100)\n",
    "model.fit(train_x, train_y)\n",
    "\n",
    "val_x = train_x[model.val_idx, :]\n",
    "val_y = train_y[model.val_idx, :]\n",
    "tr_x = train_x[model.tr_idx, :]\n",
    "tr_y = train_y[model.tr_idx, :]\n",
    "pred_train = model.predict(tr_x)\n",
    "pred_val = model.predict(val_x)\n",
    "pred_test = model.predict(test_x)\n",
    "gaminet_stat = np.hstack([np.round(get_metric(tr_y, pred_train),5), \n",
    "                      np.round(get_metric(val_y, pred_val),5),\n",
    "                      np.round(get_metric(test_y, pred_test),5)])\n",
    "print(gaminet_stat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simu_dir = \"./results/\"\n",
    "if not os.path.exists(simu_dir):\n",
    "    os.makedirs(simu_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feature_importance(data_dict, save_png=True, folder=simu_dir, name='s1_feature')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = model.global_explain(save_dict=False)\n",
    "global_visualize_wo_density(data_dict, save_png=True, folder=simu_dir, name='s1_global')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict_local = model.local_explain(train_x[[0]], train_y[[0]], save_dict=False)\n",
    "local_visualize(data_dict_local, save_png=True, folder=simu_dir, name='s1_local')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict_logs = model.summary_logs(save_dict=False, folder=folder, name=\"s1_logs\")\n",
    "plot_trajectory(data_dict_logs, folder=folder, name=\"s1_traj_plot\", log_scale=True, save_png=True, save_eps=False)\n",
    "plot_regularization(data_dict_logs, folder=folder, name=\"s1_regu_plot\", log_scale=True, save_png=True, save_eps=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf2)",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
